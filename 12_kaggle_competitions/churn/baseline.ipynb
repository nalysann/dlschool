{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"align: center;\">\n",
    "    <img align=center src=\"../../img/dls_logo.jpg\" width=500 height=500>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"text-align: center;\">\n",
    "    Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ\n",
    "</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlB-owfaEEYs"
   },
   "source": [
    "Это домашнее задание будет посвящено полноценному решению задачи машинного обучения.\n",
    "\n",
    "Есть две части этого домашнего задания:\n",
    "\n",
    "* Сделать полноценный отчёт о вашей работе: как вы обработали данные, какие модели попробовали и какие результаты получились (максимум 10 баллов). За каждую выполненную часть будет начислено определённое количество баллов.\n",
    "\n",
    "* Лучшее решение отправить в соревнование на [kaggle](https://www.kaggle.com/t/f50bc21dbe0e42dabe5e32a21f2e5235) (максимум 5 баллов). За прохождение определенных порогов будут начисляться баллы.\n",
    "\n",
    "Обе части будут проверяться в формате **peer-review**. Т.е. вашу посылку на Stepik будут проверять несколько других студентов и аггрегация их оценок будет выставлена в качестве итоговой оценки. В то же время вам тоже нужно будет проверить несколько других учеников.\n",
    "\n",
    "Пожалуйста, делайте свою работу чистой и понятной, чтобы облегчить проверку. Если у вас будут проблемы с решением или хочется совета, то пишите в наш чат в телеграме или в лс @runfme. Если вы захотите проаппелировать оценку, то пипшите в лс @runfme.\n",
    "\n",
    "Во всех пунктах указания - это минимальный набор вещей, которые стоит сделать. Если вы можете сделать какой-то шаг лучше или добавить что-то своё - дерзайте!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как проверять?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu_JvqcBEN8Y"
   },
   "source": [
    "Ставьте полный балл, если выполнены все рекомендации или сделано что-то более интересное и сложное. За каждый отсустствующий пункт из рекомендаций снижайте оценку на 1 балл."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ninJ63mJEEYt"
   },
   "source": [
    "Перед решением любой задачи важно понимать, как будет оцениваться ваше решение. В данном случае мы используем стандартную для задачи классификации метрику **ROC-AUC**. Ее можно вычислить, используя только предсказанные вероятности и истинные классы без конкретного порога классификации, плюс она работает, даже если классы в данных сильно несбалансированы (примеров одного класса в десятки раз больше примеров другого). Именно поэтому она очень удобна для соревнований.\n",
    "\n",
    "Посчитать её легко:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQIrka7yEEYu",
    "outputId": "ef45a9f2-7571-47b1-e697-b474b65cb0fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = [\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "]\n",
    "\n",
    "y_predictions = [\n",
    "    0.1,\n",
    "    0.9,\n",
    "    0.4,\n",
    "    0.6,\n",
    "    0.61,\n",
    "]\n",
    "\n",
    "roc_auc_score(y_true, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzLqEeZKEEYz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOlxdURSEEY3"
   },
   "source": [
    "1. Посмотрите на случайные строчки.\n",
    "\n",
    "2. Посмотрите, есть ли в датасете незаполненные значения (`nan`) с помощью `data.isna()` или `data.info()` и, если нужно, замените их на что-то. Будет хорошо, если вы построите табличку с количеством `nan` в каждой колонке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw-Brue9EEY3"
   },
   "outputs": [],
   "source": [
    "# загрузим данные\n",
    "data_train = pd.read_csv('data/train.csv')\n",
    "data_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgnkkF5bEEY9"
   },
   "outputs": [],
   "source": [
    "# для вашего удобства списки с именами разных столбцов\n",
    "\n",
    "# числовые признаки\n",
    "num_cols = [\n",
    "    'ClientPeriod',\n",
    "    'MonthlySpending',\n",
    "    'TotalSpent',\n",
    "]\n",
    "\n",
    "# категориальные признаки\n",
    "cat_cols = [\n",
    "    'Sex',\n",
    "    'IsSeniorCitizen',\n",
    "    'HasPartner',\n",
    "    'HasChild',\n",
    "    'HasPhoneService',\n",
    "    'HasMultiplePhoneNumbers',\n",
    "    'HasInternetService',\n",
    "    'HasOnlineSecurityService',\n",
    "    'HasOnlineBackup',\n",
    "    'HasDeviceProtection',\n",
    "    'HasTechSupportAccess',\n",
    "    'HasOnlineTV',\n",
    "    'HasMovieSubscription',\n",
    "    'HasContractPhone',\n",
    "    'IsBillingPaperless',\n",
    "    'PaymentMethod',\n",
    "]\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "\n",
    "target_col = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHC6gWabEEZA"
   },
   "outputs": [],
   "source": [
    "# помотрим на 5 случайных строк обучающего датасета\n",
    "data_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# помотрим на 5 случайных строк тестового датасета\n",
    "data_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на общую информацию по обучающему датасету\n",
    "# видим, что незаполненных значений нет,\n",
    "# однако тип столбца 'TotalSpent' почему-то object, а не float\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на общую информацию по тестовому датасету\n",
    "# видим, что незаполненных значений тоже нет,\n",
    "# а со столбцом 'TotatSpent' та же ситуация\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дополнительно проверим значения в каждом из столбцов\n",
    "for feature in feature_cols:\n",
    "    print(data_train[feature].value_counts())\n",
    "    print('-' * 30)\n",
    "    \n",
    "print(data_train[target_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видим, что в обучающем датасете в столбце 'TotalSpent'\n",
    "# есть 9 пробелов, посмотрим на эти записи\n",
    "data_train[data_train['TotalSpent'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видим, что это новые клиенты ('ClientPeriod' == 0),\n",
    "# поэтому заменим 'TotalSpent' в этих строках на 0.0\n",
    "data_train.replace(' ', 0.0, inplace=True)\n",
    "\n",
    "# теперь приведём все значения в колонке 'TotalSpent' к типу float64\n",
    "data_train['TotalSpent'] = pd.to_numeric(data_train['TotalSpent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим, нет ли такой же ситуации в тестовом датасете\n",
    "data_test[data_test['TotalSpent'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видим два таких же кейса\n",
    "# проделаем аналогичные манипуляции\n",
    "data_test.replace(' ', 0.0, inplace=True)\n",
    "data_test['TotalSpent'] = pd.to_numeric(data_test['TotalSpent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним\n",
    "data_train_orig = data_train.copy()\n",
    "data_test_orig = data_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK370bPCEEZD"
   },
   "source": [
    "1. Для численных призанков постройте гистограмму (`plt.hist`) или boxplot (`plt.boxplot`). Для категориальных посчитайте количество каждого значения для каждого признака. Для каждой колонки надо сделать `data.value_counts()` и построить bar диаграммы (`plt.bar`) или круговые диаграммы (`plt.pie`) (хорошо, если вы сможете это сделать на одном графике с помощью `plt.subplots`). \n",
    "\n",
    "2. Посмотрите на распределение целевой переменной и скажите, являются ли классы несбалансированными.\n",
    "\n",
    "3. (Если будет желание) Поиграйте с разными библиотеками для визуализации - **sns**, **pandas_visual_analysis**, etc.\n",
    "\n",
    "Второй пункт очень важен, потому что существуют задачи классификации с несбалансированными классами. Например, это может значить, что в датасете намного больше примеров $0$ класса. В таких случаях нужно: 1) не использовать `accuracy` как метрику, 2) использовать методы борьбы с **imbalanced dataset** (обычно, если датасет сильно несбалансирован, т.е. класса $1$ в $20$ раз меньше класса $0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZkbgFJZEEZE"
   },
   "outputs": [],
   "source": [
    "# распределение численных признаков в обучающем датасете\n",
    "data_train[num_cols].hist(figsize=(15, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распределение численных признаков в тестовом датасете\n",
    "# примерно совпадает с распределением в обучающем датасете\n",
    "data_test[num_cols].hist(figsize=(15, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на распределение категориальных\n",
    "# признаков в обучающем датасете\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.05)\n",
    "\n",
    "for i, feature in enumerate(cat_cols):\n",
    "    fig.add_subplot(axs[i // 4, i % 4])\n",
    "    data_train[feature].value_counts().plot(kind='pie', title=feature)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на распределение категориальных\n",
    "# признаков в тестовом датасете\n",
    "# как и в случае численных признаков распределение\n",
    "# соответствует распределению на обучающем датасете\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.05)\n",
    "\n",
    "for i, feature in enumerate(cat_cols):\n",
    "    fig.add_subplot(axs[i // 4, i % 4])\n",
    "    data_test[feature].value_counts().plot(kind='pie', title=feature)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распределение целевой переменной\n",
    "# соотношение классов примерно 3:1\n",
    "# классы не являются сбалансированными, но и очень\n",
    "# сильного перекоса в пользу одного из классов тоже нет\n",
    "data_train[target_col].value_counts().plot(kind='pie', title=target_col)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg60u3QDEEZH"
   },
   "source": [
    "(Дополнительно) Если вы нашли какие-то ошибки в данных или выбросы, то можете их убрать. Тут можно поэксперементировать с обработкой данных как угодно, но не за баллы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwfksF1gEEZI"
   },
   "outputs": [],
   "source": [
    "# I'm to lazy for this stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение линейных моделей (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DviiJd8REEZK"
   },
   "source": [
    "1. Обработайте данные для того, чтобы к ним можно было применить `LogisticRegression`. Т.е. отнормируйте числовые признаки, а категориальные закодируйте с помощью one-hot encoding'а.\n",
    "\n",
    "2. С помощью кроссвалидации или разделения на train/valid выборку протестируйте разные значения гиперпараметра `C` и выберите лучший (можно тестировать С=100, 10, 1, 0.1, 0.01, 0.001) по метрике ROC-AUC.\n",
    "\n",
    "Если вы разделяете на train/valid, то используйте `LogisticRegressionCV`. Он сам при вызове `.fit()` подберет параметр `С` (не забудьте передать `scroing='roc_auc'`, чтобы при кроссвалидации сравнивались значения этой метрики, и `refit=True`, чтобы модель обучилась на всём датасете с лучшим параметром `C`). \n",
    "\n",
    "(более сложный вариант) Если вы будете использовать кроссвалидацию, то преобразования данных и `LogisticRegression` нужно соединить в один pipeline с помощью `make_pipeline`, как это делалось во втором семинаре. Потом pipeline надо передать в `GridSearchCV`. Для one-hot encoding'a можно испльзовать комбинацию `LabelEncoder` + `OneHotEncoder` (сначала превращаем строчки в числа, а потом числа првращаем в one-hot вектора)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHCLDmwqEEZL"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим численные и категориальные признаки\n",
    "# а также целевую переменную\n",
    "num_data_train = data_train[num_cols]\n",
    "cat_data_train = data_train[cat_cols]\n",
    "target = data_train[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2Yv3uYtEEZO"
   },
   "outputs": [],
   "source": [
    "# нормируем и центрируем численные признаки\n",
    "num_data_train = scaler.fit_transform(num_data_train)\n",
    "# применяем OHE к категориальным признакам\n",
    "cat_data_train = encoder.fit_transform(cat_data_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сливаем обратно\n",
    "data_train = np.concatenate((num_data_train, cat_data_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаём модель и обучаем\n",
    "logreg_clf = LogisticRegressionCV(scoring='roc_auc', refit=True, random_state=42)\n",
    "\n",
    "logreg_clf.fit(data_train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVahy6JKEEZQ"
   },
   "source": [
    "Выпишите какое лучшее качество и с какими параметрами вам удалось получить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметр C\n",
    "logreg_clf.C_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# качество на обучающем датасете\n",
    "target_pred = logreg_clf.predict_proba(data_train)[:, 1]\n",
    "\n",
    "train_score = roc_auc_score(target, target_pred)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение градиентного бустинга (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlTeVy7fEEZR"
   },
   "source": [
    "Если вы хотите получить баллы за точный ответ, то стоит попробовать градиентный бустинг. Часто градиентный бустинг с дефолтными параметрами даст вам $80\\%$ результата за $0\\%$ усилий.\n",
    "\n",
    "Мы будем использовать `CatBoost`, поэтому нам не надо кодировать категориальные признаки. `CatBoost` сделает это сам (в `.fit()` надо передать `cat_features=cat_cols`). А численные признаки нормировать для моделей, основанных на деревьях, не нужно.\n",
    "\n",
    "1. Разделите выборку на train/valid. Протестируйте `CatBoost` cо стандартными параметрами.\n",
    "\n",
    "2. Протестируйте разные значения параметров количества деревьев и learning_rate'а и выберите лучшую по метрике ROC-AUC комбинацию. \n",
    "\n",
    "(Дополнительно) Есть некоторые сложности с тем, чтобы использовать `CatBoostClassifier` вместе с `GridSearchCV`, поэтому мы не просим использовать кроссвалидацию. Но можете попробовать :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fioxxlp-EEZS"
   },
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отделим колонку с целевой переменной\n",
    "data_train = data_train_orig[num_cols + cat_cols]\n",
    "target = data_train_orig[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим обучающий датасет на train/valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data_train,\n",
    "                                                      target,\n",
    "                                                      train_size=0.8,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запустим со стандартными параметрами\n",
    "def_catboost_clf = catboost.CatBoostClassifier(cat_features=cat_cols, eval_metric='AUC')\n",
    "\n",
    "# X_train = data_train\n",
    "# y_train = target\n",
    "\n",
    "def_catboost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# слабенько :(\n",
    "y_pred = def_catboost_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "valid_score = roc_auc_score(y_valid, y_pred)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиграемся с параметрами\n",
    "grid_catboost_clf = catboost.CatBoostClassifier(cat_features=cat_cols, eval_metric='AUC')\n",
    "\n",
    "grid = {\n",
    "    'n_estimators': [100, 200, 400, 800, 1000],\n",
    "    'learning_rate': [0.005, 0.01, 0.03, 0.06, 0.1],\n",
    "}\n",
    "\n",
    "grid_search_result = grid_catboost_clf.grid_search(grid,\n",
    "                                                   X=data_train,\n",
    "                                                   y=target,\n",
    "                                                   plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видим, что лучший результат получился на параметрах\n",
    "# n_estimators = 200\n",
    "# learning_rate = 0.1\n",
    "# обучим классификатор с такими параметрами\n",
    "best_catboost_clf = catboost.CatBoostClassifier(cat_features=cat_cols,\n",
    "                                                eval_metric='AUC',\n",
    "                                                n_estimators=200,\n",
    "                                                learning_rate=0.1)\n",
    "\n",
    "# X_train = data_train\n",
    "# y_train = target\n",
    "\n",
    "best_catboost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf4Kjt96EEZU"
   },
   "source": [
    "Выпишите какое лучшее качество и с какими параметрами вам удалось получить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_result['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_catboost_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "valid_score = roc_auc_score(y_valid, y_pred)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDMXbvNZEEZV"
   },
   "source": [
    "## Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_P4wFNaEEZW",
    "outputId": "1fba5dfc-88e4-49e3-ed8a-afe21ae3325a"
   },
   "outputs": [],
   "source": [
    "# best_model = logreg_clf\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# encoder = OneHotEncoder()\n",
    "\n",
    "# num_data_test = data_test[num_cols]\n",
    "# cat_data_test = data_test[cat_cols]\n",
    "\n",
    "# num_data_test = scaler.fit_transform(num_data_test)\n",
    "# cat_data_test = encoder.fit_transform(cat_data_test).toarray()\n",
    "\n",
    "# data_test = np.concatenate((num_data_test, cat_data_test), axis=1)\n",
    "\n",
    "# data_submission = pd.read_csv('data/submission.csv')\n",
    "\n",
    "# data_submission['Churn'] = best_model.predict_proba(data_test)[:, 1]\n",
    "# data_submission.to_csv('data/my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfSufx0CEEZZ"
   },
   "outputs": [],
   "source": [
    "# best_model = def_catboost_clf\n",
    "\n",
    "# data_submission = pd.read_csv('data/submission.csv')\n",
    "\n",
    "# data_submission['Churn'] = best_model.predict_proba(data_test_orig)[:, 1]\n",
    "# data_submission.to_csv('data/my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_catboost_clf\n",
    "\n",
    "data_submission = pd.read_csv('data/submission.csv')\n",
    "\n",
    "data_submission['Churn'] = best_model.predict_proba(data_test_orig)[:, 1]\n",
    "data_submission.to_csv('data/my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkxjbGkVEEZc"
   },
   "source": [
    "Как выставить баллы:\n",
    "\n",
    "1. 1 >= roc auc > 0.84 - это 5 баллов\n",
    "\n",
    "2. 0.84 >= roc auc > 0.7 - это 3 балла\n",
    "\n",
    "3. 0.7 >= roc auc > 0.6 - это 1 балл\n",
    "\n",
    "4. 0.6 >= roc auc - это 0 баллов\n",
    "\n",
    "Для выполнения задания необходимо выполнить следующие шаги:\n",
    "\n",
    "* Зарегистрироваться на платформе [kaggle.com](https://www.kaggle.com/). Процесс выставления оценок будет проходить при подведении итогового рейтинга. Пожалуйста, укажите во вкладке Team -> Team name свои имя и фамилию в формате Имя_Фамилия (важно, чтобы имя и фамилия совпадали с данными на Stepik).\n",
    "\n",
    "* Обучить модель, получить файл с ответами в формате `.csv` и сдать его в конкурс. Пробуйте и экспериментируйте. Обратите внимание, что вы можете выполнять до $20$ попыток сдачи на kaggle в день.\n",
    "\n",
    "* После окончания соревнования отправить итоговый ноутбук с решением на степик.\n",
    "\n",
    "* После дедлайна проверьте посылки других участников по критериям. Для этого надо зайти на степик, скачать их ноутбук и проверить скор в соревновании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для проверяющих:**\n",
    "\n",
    "* stepik: https://stepik.org/users/62768875\n",
    "\n",
    "* telegram: @nalysann"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
