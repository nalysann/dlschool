{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"align: center;\">\n",
    "    <img align=center src=\"../img/dls_logo.jpg\" width=500 height=500>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"text-align: center;\">\n",
    "    Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ\n",
    "</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">\n",
    "    Линейная, LASSO, Ridge регрессии и их оптимизация\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Co-eo4BURtaT"
   },
   "source": [
    "Сегодня мы поработаем с оптимизацией в линейных алгоритмах (линейная регрессия и логистическая регрессия), а также разберём способы регуляризации данных методов. Для удобства данные методы будем реализовывать в виде классов в `Python` наподобие соотвествующих классов из `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjjtruRfRtaW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as sla\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ow2_tnyTRtaZ"
   },
   "source": [
    "Линейные методы предполагают, что между признаками объекта (features) и целевой переменной (target/label) существует линейная зависимость, то есть\n",
    "\n",
    "$$\n",
    "y = w_1 x_1 + w_2 x_2 + ... + w_k x_k + b,\n",
    "$$\n",
    "\n",
    "где $у$ - целевая переменная (то, что мы хотим предсказать), $x_i$ - признак объекта $x$, $w_i$ - вес $i$-го признака, $b$ - bias (смещение, свободный член).\n",
    "\n",
    "Часто предполагают, что объект $x$ содержит в себе фиктивный признак равный $1$ для представления свободного члена $b$. В этом случае формула принимает простой вид:\n",
    "\n",
    "$$\n",
    "y = \\langle w, x \\rangle,\n",
    "$$\n",
    "\n",
    "где $\\langle \\cdot, \\cdot \\rangle$ - скалярное произведение векторов $w, x \\in \\mathbb{R}^n$.\n",
    "\n",
    "В матричной форме, в случае, когда у нас есть $n$ объектов формулу можно переписать следующим образом:\n",
    "\n",
    "$$\n",
    "Y = Xw,\n",
    "$$\n",
    "\n",
    "где $Y$ - вектор-столбец размера $n$, $X$ - матрица признаков размера $n \\times m$ (каждая строка матрицы есть описание признаков объекта), $w$ - вектор весов размера $m$.\n",
    "\n",
    "**Лосс:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(y_{pred}, Y) &= \\frac{1}{n}||y_{pred} - Y||^2_2 =\\\\\n",
    "&= \\frac{1}{n}||Xw - Y||^2_2 = \\frac{1}{n}\\sum_{i=1}^{n}\\left(\\sum_{j=1}^{m} x_{ij}w_j - y_i\\right)^2 =: L(w)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Аналитическое решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXIaQEtwRtaa"
   },
   "source": [
    "Минимизация ошибки по методу наименьших квадратов даёт решение:\n",
    "\n",
    "$$\n",
    "w = (X^TX)^{-1}X^TY\n",
    "$$\n",
    "\n",
    "Реализуем класс линейной регрессии с помощью этой формулы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoNhX_C-Rtab"
   },
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # принимает на вход X, y и вычисляет веса по данной выборке\n",
    "        # не забудьте про фиктивный признак, равный 1\n",
    "        \n",
    "        n, m = X.shape\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "        else:\n",
    "            x_train = X\n",
    "\n",
    "        self.w = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # принимает на вход X и возвращает ответы модели\n",
    "        # не забудьте про фиктивный признак, равный 1\n",
    "\n",
    "        n, m = X.shape\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X_test = np.hstack((X, np.ones((n, 1))))\n",
    "        else:\n",
    "            X_test = X\n",
    "        \n",
    "        y_pred = X_test @ self.w\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHib_wKZRtae"
   },
   "source": [
    "Сначала сгенерируем искусственные данные для теста моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdM_we9sRtaf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0yIwN_UwHnE"
   },
   "outputs": [],
   "source": [
    "def linear_function(x):\n",
    "    return 5 * x + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZXnilL8Rtah"
   },
   "outputs": [],
   "source": [
    "# по признакам сгенерируем значения таргетов с некоторым шумом\n",
    "objects_num = 50\n",
    "X = np.linspace(-5, 5, objects_num)\n",
    "y = linear_function(X) + np.random.randn(objects_num) * 5\n",
    "\n",
    "# выделим половину объектов на тест\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fLI_avw2sZn"
   },
   "source": [
    "Нанесём точки выборки и зависимость на график для наглядности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601735623986,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "J2NO1seSRtak",
    "outputId": "9df96ac6-1368-4185-8588-83c40c10ea9b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, linear_function(X), label='real', c='green')\n",
    "plt.scatter(X_train, y_train, label='train', c='blue')\n",
    "plt.scatter(X_test, y_test, label='test', c='orange')\n",
    "\n",
    "plt.title(\"Generated dataset\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7NHaWnnRtao"
   },
   "source": [
    "Обучим модель на `X_train` и предскажем результаты на `X_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1601735635534,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "zT2NIYcTRtap",
    "outputId": "81ab5075-9af3-491f-b3ce-56b1597d7129"
   },
   "outputs": [],
   "source": [
    "regressor = MyLinearRegression()\n",
    "\n",
    "regressor.fit(X_train[:, np.newaxis], y_train)\n",
    "\n",
    "predictions = regressor.predict(X_test[:, np.newaxis])\n",
    "w = regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 1821,
     "status": "ok",
     "timestamp": 1601735680271,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "-u7f3-4MRtar",
    "outputId": "b1576af8-9e52-4708-ba88-23f839958488"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "ax = None\n",
    "\n",
    "for i, types in enumerate([['train', 'test'], ['train'], ['test']]):\n",
    "    ax = plt.subplot(1, 3, i + 1, sharey=ax)\n",
    "    if 'train' in types:\n",
    "        plt.scatter(X_train, y_train, label='train', c='blue')\n",
    "    if 'test' in types:\n",
    "        plt.scatter(X_test, y_test, label='test', c='orange')\n",
    "\n",
    "    plt.plot(X, linear_function(X), label='real', c='green')\n",
    "    plt.plot(X, regressor.predict(X[:, np.newaxis]), label='predicted', c='red')\n",
    "\n",
    "    plt.xlabel('feature')\n",
    "    plt.ylabel('target')\n",
    "    plt.title(\" \".join(types))\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_Gx2hzSz1JD"
   },
   "source": [
    "Сравним с реализацией из `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1601735726993,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "BSJ1aeoEz49x",
    "outputId": "a42ae05f-cbc1-4631-9bd8-c0f16db14dfe"
   },
   "outputs": [],
   "source": [
    "sk_reg = LinearRegression().fit(X_train[:, np.newaxis], y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, linear_function(X), label='real', c='green')\n",
    "\n",
    "plt.scatter(X_train, y_train, label='train')\n",
    "plt.scatter(X_test, y_test, label='test')\n",
    "plt.plot(X, regressor.predict(X[:, np.newaxis]), label='ours', c='red', linestyle=':')\n",
    "plt.plot(X, sk_reg.predict(X[:, np.newaxis]), label='sklearn', c='cyan', linestyle=':')\n",
    "\n",
    "plt.title(\"Different Prediction\")\n",
    "plt.ylabel('target')\n",
    "plt.xlabel('feature')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1rSWDv2Rtau"
   },
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 1814,
     "status": "ok",
     "timestamp": 1601735753898,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "kS6dY-__Rtav",
    "outputId": "e80d687b-8a45-445e-a016-d6064c8554db"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "our_train_predictions = regressor.predict(X_train[:, np.newaxis])\n",
    "our_test_predictions = regressor.predict(X_test[:, np.newaxis])\n",
    "\n",
    "print('Our train MSE: ', mean_squared_error(y_train, our_train_predictions))\n",
    "print('Our test MSE: ', mean_squared_error(y_test, our_test_predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "sk_train_predictions = sk_reg.predict(X_train[:, np.newaxis])\n",
    "sk_test_predictions = sk_reg.predict(X_test[:, np.newaxis])\n",
    "\n",
    "print('sklearn train MSE: ', mean_squared_error(y_train, sk_train_predictions))\n",
    "print('sklearn test MSE: ', mean_squared_error(y_test, sk_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Градиентная оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJcy55C7Rtax"
   },
   "source": [
    "Обращение матрицы - очень тяжёлая операция. Кроме того, обратная матрица $(X^TX)^{-1}$ не всегда существует. По этим причинам мы воспользуемся методом градиентного спуска для оптимизации эмпирического риска.\n",
    "\n",
    "Градиентый спуск заключается в:\n",
    "\n",
    "1. Расчёте $\\displaystyle\\frac{\\partial{L}}{\\partial{w}}$ - градиента ошибки (значения целевой функции, то есть лосса $L(y_{pred}, y_{true})$) от значения параметров модели (весов $w$).\n",
    "\n",
    "2. Шаге спуска - изменении весов $w$ в сторону антиградиента с некоторым коэффициентом $h$ (он же **learning rate**):\n",
    "\n",
    "   $$\n",
    "   w := w - h\\frac{\\partial{L}}{\\partial{w}}\n",
    "   $$\n",
    "\n",
    "3. Повторении п.1 и п.2 пока не наблюдается сходимость (изменения ошибки малы или отсутсвуют).\n",
    "\n",
    "Как правило, чаще используют стохастический градиентный спуск (**SGD**): выбирают случайный элемент обучающей выборки и изменяют коэффициенты модели по направлению антиградиента функции потерь на этом примере.\n",
    "\n",
    "<img src=\"../img/linear_models_regularization_1.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omjlKYoHdLz6"
   },
   "source": [
    "**Цель:** реализовать новые классы линейной регрессии, в которой оптимизация проводится методами градиентного спуска.\n",
    "\n",
    "**Предполагаемая зависимость:** $Y = Xw$, где $Y \\in \\mathbb{R}^{n\\times 1}, X \\in \\mathbb{R}^{n\\times m}, w \\in \\mathbb{R}^{m\\times 1}$.\n",
    "\n",
    "**Минимизируемая функция:**\n",
    "\n",
    "$$\n",
    "L(y_{pred}, Y) = \\frac{1}{n} ||y_{pred} - Y||^2 = \\frac{1}{n}||Xw - Y||^2 = \\frac{1}{n}(Xw - Y)^T(Xw - Y) = \\frac{1}{n}(w^TX^TXw - 2Y^TXw + Y^TY)\n",
    "$$\n",
    "\n",
    "**Градиент:**\n",
    "$$\n",
    "\\frac{\\partial{L}}{\\partial{w}} = \\frac{2}{n}(X^TXw - X^TY) = \\frac{2}{n}X^T(y_{pred} - Y) \\,\\, \\in \\mathbb{R}^{m \\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTldWKmGRtay"
   },
   "outputs": [],
   "source": [
    "class MyGradientLinearRegression(MyLinearRegression):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        # передаёт именные параметры родительскому конструктору\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = None\n",
    "    \n",
    "    def fit(self, X, y, lr=0.01, max_iter=100):\n",
    "        # принимает на вход X, y и вычисляет веса по данной выборке\n",
    "        # не забудьте про фиктивный признак, равный 1\n",
    "\n",
    "        n, k = X.shape\n",
    "\n",
    "        # случайно инициализируем веса\n",
    "        if self.w is None:\n",
    "            self.w = np.random.randn(k + 1 if self.fit_intercept else k)\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "        else:\n",
    "            X_train = X\n",
    "\n",
    "        self.losses = []\n",
    "        \n",
    "        for iter_num in range(max_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            self.losses.append(mean_squared_error(y_pred, y))\n",
    "\n",
    "            grad = self._calc_gradient(X_train, y, y_pred)\n",
    "\n",
    "            assert grad.shape == self.w.shape, f'gradient shape {grad.shape} is not equal to weight shape {self.w.shape}'\n",
    "            \n",
    "            self.w -= lr * grad\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def _calc_gradient(self, X, y, y_pred):\n",
    "        grad = 2 / len(X) * np.dot(X.T, y_pred - y)\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def get_losses(self):\n",
    "        return self.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHM8kRomR4tW"
   },
   "source": [
    "Посчитаем предсказания на сгенерированном датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Sa2zbNeR1eI"
   },
   "outputs": [],
   "source": [
    "regressor = MyGradientLinearRegression(fit_intercept=True)\n",
    "\n",
    "losses = regressor.fit(X_train[:, np.newaxis], y_train, max_iter=100).get_losses()\n",
    "\n",
    "predictions = regressor.predict(X_test[:, np.newaxis])\n",
    "w = regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1601737089056,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "qISDNvboR8i-",
    "outputId": "03e64eea-bf46-4147-d103-74a8bd051532"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(X, linear_function(X), label='real', c='green')\n",
    "\n",
    "plt.scatter(X_train, y_train, label='train')\n",
    "plt.scatter(X_test, y_test, label='test')\n",
    "plt.plot(X, regressor.predict(X[:, np.newaxis]), label='predicted', c='red')\n",
    "\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOWg0RTMTN7P"
   },
   "source": [
    "Построим также график лосса во время обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1601737099212,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "G4rYhKQ4oMZk",
    "outputId": "7dcb7ce8-ce1b-4997-d5a5-e3b26630516d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.title('Gradient descent learning')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSutWICPJqmi"
   },
   "source": [
    "Добавим к нашему градиентному спуску сэмплирование мини-батча, по которому будем считать градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkO4_C6HEB9X"
   },
   "outputs": [],
   "source": [
    "class MySGDLinearRegression(MyGradientLinearRegression):\n",
    "    \n",
    "    def __init__(self, n_samples=10, **kwargs):\n",
    "        # передаёт именные параметры родительскому конструктору\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_samples = n_samples\n",
    "        self.w = None\n",
    "\n",
    "    def _calc_gradient(self, X, y, y_pred):\n",
    "        # главное отличие в SGD - это использование подвыборки для шага оптимизации\n",
    "        inds = np.random.choice(np.arange(X.shape[0]), size=min(self.n_samples, len(X)), replace=False)\n",
    "        \n",
    "        grad = 2 / len(inds) * np.dot(X[inds].T, y_pred[inds] - y[inds])\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruAZDKIhLZmx"
   },
   "source": [
    "Проведём аналогичный расчёт на сгенерированном датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ws9WBaxaKreT"
   },
   "outputs": [],
   "source": [
    "regressor = MySGDLinearRegression(fit_intercept=True)\n",
    "\n",
    "losses = regressor.fit(X_train[:, np.newaxis], y_train, max_iter=100).get_losses()\n",
    "\n",
    "predictions = regressor.predict(X_test[:, np.newaxis])\n",
    "w = regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1601737296153,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "jj7mKj94KreZ",
    "outputId": "414188f1-1f6b-4801-b2fe-ad13327987aa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, linear_function(X), label='real', c='green')\n",
    "\n",
    "plt.scatter(X_train, y_train, label='train')\n",
    "plt.scatter(X_test, y_test, label='test')\n",
    "plt.plot(X, regressor.predict(X[:, np.newaxis]), label='predicted', c='red')\n",
    "\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1601737325489,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "UzdYpx0ILwIS",
    "outputId": "80fb93f4-f3c0-4ff8-d8d6-b5d09b0c4c6c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.title('SGD learning')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB3OxINNKr40"
   },
   "source": [
    "Протестируем раличные размеры батча для расчёта градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keopB5waK5JQ"
   },
   "outputs": [],
   "source": [
    "n_samples = [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1601737419196,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "LEk2Se9VKVwN",
    "outputId": "97bfa7a6-0daf-4daf-a6bc-c20ade4d5a8f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for ns in n_samples:\n",
    "    losses = MySGDLinearRegression(fit_intercept=True, n_samples=ns).fit(\n",
    "        X_train[:, np.newaxis],\n",
    "        y_train,\n",
    "        lr=5e-3,\n",
    "        max_iter=150,\n",
    "    ).get_losses()\n",
    "    plt.plot(losses, alpha=0.5, label=f'mini-batch size = {ns}')\n",
    "\n",
    "plt.title('SGD learning')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim((0, 150))\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GrOKmdiN_eO"
   },
   "source": [
    "Как видно по графикам, размер подвыборки влияет на стабильность сходимости (чем меньше, тем больше и резче изменения весов).\n",
    "При этом количество итераций для минимизации примерно одинаково.\n",
    "\n",
    "**SGD** также обычно улучшают адаптивным уменьшением величины шага (подробнее в курсах про методы оптимизации и т.п.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf9vCXTuS4LQ"
   },
   "source": [
    "Задание аналогичное линейной регрессии, только мы переводим выходное значение в вероятность предсказания класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNlaosNrI8zU"
   },
   "source": [
    "<img src='../img/linreg_regularization_1.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De_T_s5QJ05T"
   },
   "source": [
    "Для этого воспользуемся функцией $\\displaystyle\\sigma(x) = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xh_trMBJoVt"
   },
   "source": [
    "<img src='../img/linreg_regularization_2.png' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avVeG3umKJme"
   },
   "source": [
    "Задача теперь формулируется так:\n",
    "\n",
    "**Предсказания:**\n",
    "\n",
    "$$\n",
    "y_{pred}(x, w) = \\frac{1}{1 + e^{-\\langle x, w \\rangle}}\n",
    "$$\n",
    "\n",
    "**Лосс (LogLoss):**\n",
    "\n",
    "$$\n",
    "L(w) = -y\\, log\\,y_{pred} - (1-y)\\,log\\,(1-y_{pred})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71kB0ofbLoUg"
   },
   "source": [
    "<img src='../img/linreg_regularization_3.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScGlLGPSLusC"
   },
   "source": [
    "**Градиент:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{L}}{\\partial{w}}\n",
    "= \\left(-\\frac{y}{y_{pred}} + \\frac{1-y}{1-y_{pred}}\\right)\\frac{\\partial{y_{pred}}}{\\partial{w}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{y_{pred}}}{\\partial{w}} = \\frac{1}{(1+e^{-\\langle x, w \\rangle})^2} e^{-\\langle x, w \\rangle} (-x) = y_{pred}(1-y_{pred})x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{L}}{\\partial{w}} = (y_{pred} - y) x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRi9CJNUSALP"
   },
   "outputs": [],
   "source": [
    "def logit(x, w):\n",
    "    return np.dot(x, w)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class MyLogisticRegression(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "    \n",
    "    def fit(self, X, y, max_iter=100, lr=0.1):\n",
    "        # принимает на вход X, y и вычисляет веса по данной выборке.\n",
    "        # множество допустимых классов: {1, -1}\n",
    "        # не забудьте про фиктивный признак равный 1!\n",
    "        \n",
    "        n, k = X.shape\n",
    "        \n",
    "        if self.w is None:\n",
    "            self.w = np.random.randn(k + 1)\n",
    "               \n",
    "        losses = []\n",
    "        \n",
    "        X_train = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
    "        \n",
    "        for iter_num in range(max_iter):\n",
    "            y_pred = sigmoid(logit(X_train, self.w))\n",
    "            grad = np.dot(X_train.T, y_pred - y) / len(X_train)\n",
    "\n",
    "            self.w -= lr * grad\n",
    "\n",
    "            losses.append(self.__loss(y, y_pred))\n",
    "        \n",
    "        return losses\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        # принимает на вход X и возвращает ответы модели\n",
    "        n, k = X.shape\n",
    "        X_ = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
    "        return sigmoid(logit(X_, self.w))\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return self.predict_proba(X) >= threshold\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.w\n",
    "      \n",
    "    def __loss(self, y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
    "        return np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1601738168478,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "_KLNlzOTTMU7",
    "outputId": "936acdc4-2bc9-401e-ffce-f8cc01adc7de"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=1000, centers=[[-2, 0.5], [3, -0.5]], cluster_std=1, random_state=42)\n",
    "\n",
    "colors = (\"red\", \"green\")\n",
    "colored_y = np.zeros(y.size, dtype=str)\n",
    "\n",
    "for i, cl in enumerate([0, 1]):\n",
    "    colored_y[y == cl] = str(colors[i])\n",
    "    \n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colored_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBOGLUOZajFI"
   },
   "outputs": [],
   "source": [
    "clf = MyLogisticRegression()\n",
    "\n",
    "clf.fit(X, y, max_iter=1000)\n",
    "\n",
    "w = clf.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "executionInfo": {
     "elapsed": 2728,
     "status": "ok",
     "timestamp": 1601738179701,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "DYE99GJLeJoc",
    "outputId": "bfa9389a-fe26-4b5d-c2d3-5566ba74b680"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "eps = 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(np.min(X[:, 0]) - eps, np.max(X[:, 0]) + eps, 200),\n",
    "                     np.linspace(np.min(X[:, 1]) - eps, np.max(X[:, 1]) + eps, 200))\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colored_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. О регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRoRKVq43yvE"
   },
   "source": [
    "Зачастую модель обучается на каких-то зашумленных данных. Веса модели после обучения подбираются для уменьшения ошибки целевой функции. На различных выборках модель может обучаться по-разному, но нам бы хотелось вычленять основную зависимость примерно одинаково, то есть **не переобучаться (overfit)** на данных. Иначе обучившись на одном сете, мы можем получать неожиданный результат на других данных.\n",
    "\n",
    "То есть мы хотели бы штрафовать модель за ее сложность, чтобы выискивать более простые зависимости.\n",
    "\n",
    "Одним словом нужно достигать некий bias/variance баланс для модели.\n",
    "\n",
    "<img src='../img/linreg_regularization_4.png' width=600>\n",
    "\n",
    "Для линейной модели дополнительные ограничения на веса выполняют роль регуляризации. Различают:\n",
    "* $l_1$ регуляризацию (LASSO, least absolute shrinkage and selection operator), учитывание $||w||_1$\n",
    "\n",
    "* $l_2$ регуляризацию (Ridge), учитывание $||w||^2_2$\n",
    "\n",
    "* Elastic net - комбинация двух предыдущих"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AieEOW9_iAWd"
   },
   "source": [
    "Далее напишем свои классы для Ridge и LASSO регрессий. Протестируем их на выборке из первого задания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1hT5UQ0Xk9r"
   },
   "outputs": [],
   "source": [
    "objects_num = 50\n",
    "X = np.linspace(-5, 5, objects_num)\n",
    "y = linear_function(X) + np.random.randn(objects_num) * 5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ridge регрессия ($l_2$ регуляризация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDY8EJmPsrCy"
   },
   "source": [
    "В Ridge мы штрафуем модель также на сумму квадратов всех её весов, таким образом:\n",
    "\n",
    "**Лосс:** $L(w) = ||Xw - Y||^2_2 + \\lambda||w||^2_2$, где $\\lambda$ - гиперпараметр, отвечающий за степень регуляризации.\n",
    "\n",
    "В привычном понимании:\n",
    "\n",
    "**Лосс:** $L(w) = \\sum_{i=1}^n\\left(\\sum_{j=1}^{m} x_{ij}w_j - y_i\\right)^2 + \\lambda\\sum_{j=1}^{m}w_j^2$\n",
    "\n",
    "Что стоит сказать про значения признаков? Они должны быть стандартизованы для одинаковых штрафов относительно друг друга (используется связка с `sklearn.preprocessing.StandardScaler`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YjPt41xZYZB"
   },
   "source": [
    "Кстати, наблюдается довольно интересная особенность Ridge, из-за того как мы определили функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1601738539479,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "fJlH1_31LDjw",
    "outputId": "aa8bef3a-c4df-42eb-fd1b-bbc4abc56228"
   },
   "outputs": [],
   "source": [
    "reg = Ridge(alpha=1).fit(np.hstack((X, X, X))[:, np.newaxis], np.hstack((y, y, y)))\n",
    "np.append(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1601738542960,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "xSAI-dy0Nw5C",
    "outputId": "eec15a49-05cd-4cef-c079-08760f1433fd"
   },
   "outputs": [],
   "source": [
    "reg = Ridge(alpha=1/3).fit(X[:, np.newaxis], y)\n",
    "np.append(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Аналитическое решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY7Gn7kIDLrc"
   },
   "source": [
    "Из курса статистики известно, если:\n",
    "\n",
    "$$\n",
    "L(w) = ||Xw - Y||^2_2 + ||\\Gamma w||^2_2\n",
    "$$\n",
    "\n",
    "минимизируется при:\n",
    "\n",
    "$$\n",
    "w = (X^TX + \\Gamma^T \\Gamma)^{-1}X^TY\n",
    "$$\n",
    "\n",
    "В нашем случае $\\Gamma^T\\Gamma = \\lambda I$, если нет свободного члена, иначе:\n",
    "$\\Gamma^T\\Gamma =\n",
    "\\left(\\begin{matrix}\n",
    "\\lambda I & 0 \\\\\n",
    "0 & 0\n",
    "\\end{matrix}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xtV_gDCEDYG"
   },
   "outputs": [],
   "source": [
    "class MyRidgeRegression(MyLinearRegression):\n",
    "    \n",
    "    def __init__(self, alpha=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, m = X.shape\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "        else:\n",
    "            X_train = X\n",
    "        \n",
    "        # найдём аналитическое решение\n",
    "        lambda_I = self.alpha * np.eye(X_train.shape[1])\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            lambda_I[-1, -1] = 0\n",
    "\n",
    "        self.w = np.linalg.inv(X_train.T @ X_train + lambda_I) @ X_train.T @ y\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgylCmpbIX8l"
   },
   "source": [
    "Протестируем решение на нашем датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocBpQgc9BvSK"
   },
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "regressor = MyRidgeRegression(alpha=alpha).fit(X_train[:, np.newaxis], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c00MrkrKzTc"
   },
   "source": [
    "Проверим работу, сравнив с `linear_model.Ridge` из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1601738863894,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "N8VOoZYUB-ne",
    "outputId": "97ee94c1-9825-4ee4-c5a9-5ddafde5e4f4"
   },
   "outputs": [],
   "source": [
    "sklearn_reg = Ridge(alpha=alpha).fit(X_train[:, np.newaxis], y_train)\n",
    "assert np.allclose(regressor.get_weights(), np.append(sklearn_reg.coef_, sklearn_reg.intercept_))\n",
    "regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 1911,
     "status": "ok",
     "timestamp": 1601738885315,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "F8m8dS8JCDIu",
    "outputId": "b480349b-5faa-4bbc-fb91-ae80f99775a7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "ax = None\n",
    "\n",
    "for i, types in enumerate([['train', 'test'], ['train'], ['test']]):\n",
    "    ax = plt.subplot(1, 3, i + 1, sharey=ax)\n",
    "    if 'train' in types:\n",
    "        plt.scatter(X_train, y_train, label='train', c='blue')\n",
    "    if 'test' in types:\n",
    "        plt.scatter(X_test, y_test, label='test', c='orange')\n",
    "\n",
    "    plt.plot(X, linear_function(X), label='real', c='green')\n",
    "    plt.plot(X, regressor.predict(X[:, np.newaxis]), label='predicted', c='red')\n",
    "\n",
    "    plt.ylabel('target')\n",
    "    plt.xlabel('feature')\n",
    "    plt.title(\" \".join(types))\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL1-wqDpIRqm"
   },
   "source": [
    "Аналогично предыдущим заданиям нужно рассчитать значение градиента $\\displaystyle\\frac{\\partial{L}}{\\partial{w}}$.\n",
    "\n",
    "**Имеем:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}L(w) &= ||Xw - Y||^2_2 + ||\\Gamma w||^2_2\n",
    "= (Xw - Y)^T(Xw - Y) + w^T\\Gamma^T\\Gamma w = \\\\\n",
    "&= w^TX^TXw - 2Y^TXw + Y^TY + w^T\\Gamma^T\\Gamma w =\n",
    "w^T(X^TX + \\Gamma^T\\Gamma)w - 2Y^TXw + Y^TY\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Градиент:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{L}}{\\partial{w}}\n",
    "= 2(X^TX + \\Gamma^T\\Gamma)w - 2X^TY\n",
    "$$\n",
    "\n",
    "Будем также усреднять значения лосса по батчу данных (появится $\\displaystyle\\frac{1}{n_{sample}}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNhGU147Zyj7"
   },
   "source": [
    "Реализуем наш класс Ridge регрессии используя стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R39nSHvmIRqp"
   },
   "outputs": [],
   "source": [
    "class MySGDRidge(MySGDLinearRegression):\n",
    "    def __init__(self, alpha=1.0, **kwargs):\n",
    "        # передаёт именные параметры родительскому конструктору\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "\n",
    "    def _calc_gradient(self, X, y, y_pred):\n",
    "        # главное отличие в SGD - это использование подвыборки для шага оптимизации\n",
    "        inds = np.random.choice(np.arange(X.shape[0]), size=self.n_samples, replace=False)\n",
    "\n",
    "        lambda_I = self.alpha * np.eye(self.w.shape[0])\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            lambda_I[-1, -1] = 0\n",
    "\n",
    "        grad = 2 * (X[inds].T @ X[inds] / self.n_samples + lambda_I) @ self.w\n",
    "        grad -= 2 * X[inds].T @ y[inds] / self.n_samples\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 3359,
     "status": "ok",
     "timestamp": 1601739203184,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "LrDE972zOnEf",
    "outputId": "b3c6355f-500f-4c0e-87b5-7f79248b7f06"
   },
   "outputs": [],
   "source": [
    "regressor = MySGDRidge(alpha=1.0, n_samples=20).fit(X[:, np.newaxis], y, max_iter=1000, lr=0.01)\n",
    "l = regressor.get_losses()\n",
    "regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1601739213534,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "BrXDsPahWR1D",
    "outputId": "08046c5a-64af-4d00-a9ef-fe052ae36f56"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, linear_function(X), label='real', c='green')\n",
    "\n",
    "plt.scatter(X_train, y_train, label='train')\n",
    "plt.scatter(X_test, y_test, label='test')\n",
    "plt.plot(X, regressor.predict(X[:, np.newaxis]), label='predicted', c='red')\n",
    "\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1601739220484,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "ppm4v0PROrAW",
    "outputId": "c3edd790-9f13-4027-b3a6-6eb67558fb66"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(l)\n",
    "\n",
    "plt.title('Ridge learning with SGD')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LASSO регрессия ($l_1$ регуляризация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nc-MKy0zb1D7"
   },
   "source": [
    "В LASSO мы штрафуем модель также **на сумму модулей всех ее весов** (на $l_1$-норму весов), таким образом:\n",
    "\n",
    "**Лосс:** $L(w) = ||Xw - Y||^2_2 + \\lambda ||w||_1$, где $\\lambda$ - гиперпараметр, отвечающий за степень регуляризации.\n",
    "\n",
    "В привычном понимании:\n",
    "\n",
    "**Лосс:** $L(w) = \\sum_{i=1}^n\\left(\\sum_{j=1}^{m} x_{ij}w_j - y_i\\right)^2 + \\lambda\\sum_{j=1}^{m}|w_j|$\n",
    "\n",
    "Признаки опять же должны быть стандартизованы для одинаковых штрафов относительно друг друга!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Lasso наблюдается поведение, которое нам бы и хотелось видеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1601739509528,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "QgdUirBDb1D9",
    "outputId": "a2a8dae8-a85e-4d82-908f-0387b381299c"
   },
   "outputs": [],
   "source": [
    "reg = Lasso(alpha=1.0).fit(np.hstack((X, X, X))[:, np.newaxis], np.hstack((y, y, y)))\n",
    "np.append(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1601739512723,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "JaxC_O6Ab1EB",
    "outputId": "d87794e5-dc73-40e6-9355-fe9e9166377d"
   },
   "outputs": [],
   "source": [
    "reg = Lasso(alpha=1.0).fit(X[:, np.newaxis], y)\n",
    "np.append(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Аналитическое решение (в общем случае не находится)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c71DTs71b1ED"
   },
   "source": [
    "Изменение в типе нормы (с $l_2$ на $l_1$) может и выглядит достаточно просто, но при этом поведение регуляризации сильно меняется.\n",
    "\n",
    "Решение находится достаточно просто если столбцы матрицы $X$ ортогональны (см. [stack exchange](https://stats.stackexchange.com/questions/17781/derivation-of-closed-form-lasso-solution)).\n",
    "\n",
    "Также можно рассматривать эквивалентную задачу оптимизции (на что мы и будем ссылаться). Следующие задачи эквивалентны (из [теоремы Каруша-Куна-Таккера](https://ru.wikipedia.org/wiki/Условия_Каруша_—_Куна_—_Таккера)):\n",
    "\n",
    "1. Для некоторого $c$:\n",
    "$\n",
    "\\begin{cases}\n",
    "\\displaystyle L_2(w) \\rightarrow \\min_w \\\\\n",
    "||w||_1 \\leq c\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "2. Для некоторого $\\lambda$: $L(w) = L_2(w) + \\lambda||w||_1 \\rightarrow \\displaystyle \\min_w$\n",
    "\n",
    "Первое представление задачи даёт нам геометрический смысл, как минимизация на гранях многомерного ромба."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CknBUa65mae1"
   },
   "source": [
    "<img src='../img/linreg_regularization_5.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ0MjcO0b1EN"
   },
   "source": [
    "В реализации `sklearn.linear_model.Lasso` используется так называемый **Stochastic Coordinat Descent (aka shooting algorithm)**, где веса пересчитываются по очереди.\n",
    "\n",
    "<img src='../img/linreg_regularization_6.png' width=800>\n",
    "\n",
    "Его мы реализовывать не будем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luCaPCmVGL1r"
   },
   "source": [
    "Аналогично предыдущим заданиям для SGD нужно рассчитать значение градиента $\\displaystyle\\frac{\\partial{L}}{\\partial{w}}$.\n",
    "\n",
    "**Лосс:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}L(w) &= ||Xw - Y||^2_2 + ||\\Gamma w||_1\n",
    "= (Xw - Y)^T(Xw - Y) + ||\\Gamma w||_1 = \\\\\n",
    "&= w^TX^TXw - 2Y^TXw + Y^TY + \\lambda\\sum_{i=1}^{m-1}|w|\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Градиент:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{L}}{\\partial{w}}\n",
    "= 2(X^TXw - X^TY) + \\lambda sign(w)\n",
    "= 2X^T(y_{pred} - Y) + \\lambda sign(w)\n",
    "$$\n",
    "\n",
    "где для приближения будем считать что $|\\cdot|$ - дифференцируемая функция, ее производной является $sign(\\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ql0bUwMb1EO"
   },
   "source": [
    "Реализуем наш класс Lasso регрессии используя стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyCwVEacb1EO"
   },
   "outputs": [],
   "source": [
    "def soft_sign(x, eps=1e-7):\n",
    "    if abs(x) > eps:\n",
    "        return np.sign(x)\n",
    "    return x / eps\n",
    "\n",
    "\n",
    "np_soft_sign = np.vectorize(soft_sign)\n",
    "\n",
    "class MySGDLasso(MySGDLinearRegression):\n",
    "    def __init__(self, alpha=1.0, **kwargs):\n",
    "        # передаёт именные параметры родительскому конструктору\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "\n",
    "    def _calc_gradient(self, X, y, y_pred):\n",
    "        # главное отличие в SGD - это использование подвыборки для шага оптимизации\n",
    "        inds = np.random.choice(np.arange(X.shape[0]), size=self.n_samples, replace=False)\n",
    "\n",
    "        sign_w = np_soft_sign(self.w)\n",
    "        if self.fit_intercept:\n",
    "            sign_w[-1] = 0\n",
    "\n",
    "        grad = 2 / self.n_samples * X[inds].T @ (y_pred[inds] - y[inds])\n",
    "        grad += self.alpha * sign_w\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWpoS7xmveXa"
   },
   "source": [
    "Протестируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1601741069034,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "g03M0f7ib1ES",
    "outputId": "de8e2295-136a-4803-b618-503634d8b371"
   },
   "outputs": [],
   "source": [
    "regressor = MySGDLasso(alpha=1., n_samples=3).fit(X[:, np.newaxis], y, max_iter=1000, lr=0.01)\n",
    "l = regressor.get_losses()\n",
    "regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 3001,
     "status": "ok",
     "timestamp": 1601740958225,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "cPFnhfXJvgzF",
    "outputId": "28ed42ce-058b-4d52-ba4d-bf5906799c99"
   },
   "outputs": [],
   "source": [
    "sklearn_reg = Lasso().fit(X[:, np.newaxis], y)\n",
    "np.append(sklearn_reg.coef_, sklearn_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1601741050653,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "t8OIufLQb1EU",
    "outputId": "f86fd294-73d7-4a20-8b8b-744a01044adf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, linear_function(X), label='real', c='green')\n",
    "\n",
    "plt.scatter(X_train, y_train, label='train')\n",
    "plt.scatter(X_test, y_test, label='test')\n",
    "plt.plot(X, regressor.predict(X[:, np.newaxis]), label='predicted', c='red')\n",
    "\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 2176,
     "status": "ok",
     "timestamp": 1601741074823,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "waB1gP42b1EW",
    "outputId": "7cb2af2b-8f87-4504-ad9d-a74ddbc896f3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(l)\n",
    "\n",
    "plt.title('Lasso learning with SGD')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Различия LASSO и Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DBMXR3FiB_F"
   },
   "source": [
    "<img src='../img/linreg_regularization_7.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ker3ZqpRjhIA"
   },
   "source": [
    "Между $l_1$ и $l_2$ регуляризациями существует несколько различий:\n",
    "\n",
    "* **сложнее считать** из-за недифференцируемых углов шара в $l_1$-норме (в значении нуля для признаков)\n",
    "\n",
    "* из-за отсутствия надлежащих поворотов с низким изменением лосса, появляется **зануление весов** для некоторых признаков\n",
    "\n",
    "* **отсутствие аналитического решения** делает вычисления и теоретические значения весов при регуляризации более сложными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NitM79arKQ_9"
   },
   "source": [
    "Протестируем методы на реальных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 3700,
     "status": "ok",
     "timestamp": 1601741735371,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "6rBRCj1AMY73",
    "outputId": "c73faad4-8b0f-4ee2-8212-5b3c9e28703b"
   },
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lj2ILcOXiPdS"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 2636,
     "status": "ok",
     "timestamp": 1601741772361,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "MTvjumTJKdnp",
    "outputId": "be3a3b48-c052-4cd2-acc2-cf8baaae383c"
   },
   "outputs": [],
   "source": [
    "data = load_iris(as_frame=True).frame\n",
    "names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "executionInfo": {
     "elapsed": 10113,
     "status": "ok",
     "timestamp": 1601741826723,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "ezvyApUoNnwS",
    "outputId": "1ff22551-ebf2-4c6a-d39d-912b858f0537"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrShSh97Kq5l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[names[:-1]], data[names[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIOi3QEOK7JM"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1601742761324,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "tJSvt5-QK__3",
    "outputId": "380352fb-6eb7-4be1-d2a7-67b1f885252d"
   },
   "outputs": [],
   "source": [
    "# cls = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     SGDClassifier(alpha=0.2, l1_ratio=0.1)\n",
    "# )\n",
    "\n",
    "cls = SGDClassifier(alpha=0.2, l1_ratio=0.1)\n",
    "\n",
    "cls = cls.fit(X_train.to_numpy(), y_train)\n",
    "preds_train = cls.predict(X_train)\n",
    "\n",
    "accuracy_score(preds_train, y_train), f1_score(preds_train, y_train, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1601742389659,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "8gDMytMBSEHG",
    "outputId": "41657172-6710-48f6-fe46-0a1f3db0cbf2"
   },
   "outputs": [],
   "source": [
    "preds_test = cls.predict(X_test)\n",
    "\n",
    "accuracy_score(preds_test, y_test), f1_score(preds_test, y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1601742409255,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "4uFpKueKSHvD",
    "outputId": "476232ff-60ef-46dd-d935-ff820892865c"
   },
   "outputs": [],
   "source": [
    "# cls[1].coef_, cls[1].intercept_\n",
    "cls.coef_, cls.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1601742811968,
     "user": {
      "displayName": "Dmitry Sadykov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgArvDSk-6HwLa1evawJTc5lunengPA8gbCs1I6nA=s64",
      "userId": "07758746379807017181"
     },
     "user_tz": -180
    },
    "id": "0Vl87U7tVVl0",
    "outputId": "d6ba9fb2-7bb6-421f-8956-dc33d6d55293"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "eps = 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(np.min(X_train[names[0]]) - eps, np.max(X_train[names[0]]) + eps, 200),\n",
    "                     np.linspace(np.min(X_train[names[1]]) - eps, np.max(X_train[names[1]]) + eps, 200))\n",
    "\n",
    "\n",
    "cls.fit(X_train[names[:2]], y_train)\n",
    "Z = cls.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "cmap_light = ListedColormap(['#AAAAFF', '#FFAAAA', '#AAFFAA'])\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "plt.scatter(X_train[names[0]], X_train[names[1]], c=y_train, cmap='brg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar,adv]linreg_regularization_unsolved.ipynb",
   "provenance": [
    {
     "file_id": "1M9z967FM9-7kHDwoHDxDLmwS58IqL_xL",
     "timestamp": 1601729590049
    },
    {
     "file_id": "1NVeCKR9Vz5qnurU1lxygpR8zigaOYt5H",
     "timestamp": 1601563204193
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
