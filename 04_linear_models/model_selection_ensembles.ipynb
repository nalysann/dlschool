{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"align: center;\">\n",
    "    <img align=center src=\"../img/dls_logo.jpg\" width=500 height=500>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"text-align: center;\">\n",
    "    Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ\n",
    "</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Напоминание: переобучение, регуляризация и кросс-валидация.\n",
    "\n",
    "2. Pipeline решения ML задачи.\n",
    "\n",
    "3. Подбор гиперпараметров и ансамблирование моделей на примере размеченных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переобучение и методы борьбы с ним"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучение - это одна из главных проблем, с которыми сталкиваются модели машинного обучения. Эффект переобучения состоит в том, что модель, подстраиваясь под обучающую выборку, \"обращает внимание\" на закономерности в выборке, которые не проявляются в общем случае и имеют характер совпадения. \n",
    "\n",
    "Переобучение проявляется тем больше, чем больше степеней свободы имеет модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Решающее дерево со слишком большой глубиной может идеально подстроиться под обучающую выборку. Параметры решающего дерева - это решающие правила во всех вершинах (всего $\\sim 2^n$ решающих правил в дереве глубины $n$).\n",
    "\n",
    "* Алгоритм $k$ ближайших соседей подстраивается под обучающую выборку и может рассматриваться как эталонный пример переобучения: любой локальный шум в данных приведёт к ошибке. Параметрами $k$-nn являются **все элементы обучающей выборки**.\n",
    "\n",
    "* Линейный алгоритм, построенный для выборки слишком маленького размера со слишком большим количеством признаков неизбежно переобучится под обучающую выборку.\n",
    "\n",
    "Во всех примерах мы видим, что при слишком большой сложности модели по сравнению с количеством элементов в обучающей выборке переобучение имеет место. Строго говоря, **переобучение есть всегда, когда имеет место принятие решения в условии неполных данных**, то есть всегда в машинном обучении.\n",
    "\n",
    "<img src='../img/model_selection_overfitting.png'>\n",
    "\n",
    "Чтобы нивелировать эффект переобучения, нужно поймать момент, в который качество на тестовой выборке начинает увеличиваться с ростом сложности модели. В этот момент обучение стоит останавливать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переобучение многочленов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смоделируем переобучение сколонность к переобучению полиномиальной зависимости с ростом степени многочлена. Сгенерируем искусственные данные из линейной зависимости с шумом и восстановим зависимость с помощью многочленов степени $1, 3, 4, 7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T10:12:43.455283Z",
     "start_time": "2020-10-11T10:12:31.683412Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T10:12:44.188193Z",
     "start_time": "2020-10-11T10:12:43.462178Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.linspace(-10, 10, 20)\n",
    "\n",
    "y = 2 * X + 3 + np.random.randn(20) * 3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, random_state=42)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train,y_train, label='Train')\n",
    "plt.scatter(X_test,y_test, label='Test')\n",
    "plt.plot(X, 2 * X + 3, color='red', lw=3, alpha=0.2)\n",
    "legend_box = plt.legend(framealpha=1).get_frame()\n",
    "legend_box.set_facecolor(\"white\")\n",
    "legend_box.set_edgecolor(\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T10:12:46.721155Z",
     "start_time": "2020-10-11T10:12:44.196157Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-12, 12, 500)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(18, 18))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, deg in enumerate([1, 3, 4, 7, 9, 20]):\n",
    "    poly = np.polyfit(X_train, y_train, deg)\n",
    "    ax[i].set_title('Polynomial fit, degree = ' + str(deg))\n",
    "    ax[i].scatter(X_train,y_train, \n",
    "                  label=f'train mse = {mean_squared_error(y_train, np.polyval(poly, X_train)):.3f}')\n",
    "    ax[i].scatter(X_test,y_test, \n",
    "                  label=f'test mse = {mean_squared_error(y_test, np.polyval(poly, X_test)):.3f}')\n",
    "    ax[i].set_ylim(-40, 40)\n",
    "    ax[i].plot(grid, np.polyval(poly, grid))\n",
    "    \n",
    "    ax[i].plot(X, 2 * X + 3, color='red', lw=1, alpha=0.4)\n",
    "    legend_box = ax[i].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "||x-y||, \\text{x, y - векторы в 2-мерном пространстве}\n",
    "$$\n",
    "\n",
    "$$\n",
    "||x - y|| = \\sqrt{(x_1 - y_1)^2 + (x_2-y_2)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "||x-y||, \\text{x, y - векторы в n-мерном пространстве}\n",
    "$$\n",
    "\n",
    "$$\n",
    "||x - y|| = \\sqrt{(x_1 - y_1)^2 + ... + (x_n-y_n)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Идея 1: регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть регуляризации состоит в том, чтобы добавлять к функции потерь слагаемое, ограничивающее рост весов модели. Например, обычная версия линейной регрессии выглядит так:\n",
    "\n",
    "$$\n",
    "\\frac{\\sum\\limits_{i=1}^{\\ell}\\left|\\left|\\langle x^i, w\\rangle - y^i\\right|\\right|^2}{\\ell} \\rightarrow \\min_{w}.\n",
    "$$\n",
    "\n",
    "Регуляризованная версия:\n",
    "\n",
    "$$\n",
    "\\frac{\\sum\\limits_{i=1}^{\\ell}\\left|\\left|\\langle x^i, w\\rangle - y^i\\right|\\right|^2}{\\ell} + \\frac{1}{C}\\left|\\left|w\\right|\\right|^2\\rightarrow \\min_{w}.\n",
    "$$\n",
    "\n",
    "Такая версия линейной регрессии называется **Ridge-регрессией**.  \n",
    "Есть также **Lasso-регрессия** и **ElasticNet**.\n",
    "\n",
    "Обычная версия логрегрессии:\n",
    "\n",
    "$$\n",
    "-\\frac{1}{\\ell}\\left( \\sum\\limits_{y^i = 1}\\ln\\sigma(\\langle x, w\\rangle) + \\sum\\limits_{y^i = -1}\\ln(1-\\sigma(\\langle x, w\\rangle))\\right)\\rightarrow \\min_{w}\n",
    "$$\n",
    "\n",
    "Регуляризованная версия:\n",
    "\n",
    "$$\n",
    "-\\frac{1}{\\ell}\\left( \\sum\\limits_{y^i = 1}\\ln\\sigma(\\langle x, w\\rangle) + \\sum\\limits_{y^i = -1}\\ln(1-\\sigma(\\langle x, w\\rangle))\\right) + \\frac{1}{C}||w||^2\\rightarrow \\min_{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Идея 2: кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/model_selection_cv.png' width=600>\n",
    "\n",
    "Картинка говорит сама за себя. Чтобы получить более стабильное предсказание и точно увидеть переобучение, можно использовать кросс-валидацию. Это ещё пригодится дальше в ноутбуке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T10:13:30.105149Z",
     "start_time": "2020-10-11T10:13:30.100123Z"
    }
   },
   "source": [
    "# Pipeline решения ML-задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/model_selection_lifecycle.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/model_selection_pipeline.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор оптимальной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы потренируемся обучению, оценке и валидации моделей, подбору оптимальных гиперпараметров, смешиванию моделей. Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $\\$50000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:19:13.272257Z",
     "start_time": "2020-10-11T11:19:13.269311Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:19:20.781390Z",
     "start_time": "2020-10-11T11:19:14.330831Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult.csv', sep=', ', header=None)\n",
    "\n",
    "# назначаем имена колонок\n",
    "columns = ('age workclass fnlwgt education educ-num marital-status occupation relationship '\n",
    "           'race sex capital-gain capital-loss hours-per-week native-country salary')\n",
    "\n",
    "numeric_indices = np.array([0, 2, 4, 10, 11, 12])\n",
    "categorical_indices = np.array([1, 3, 5, 6, 7, 8, 9, 13])\n",
    "\n",
    "# этот метод разделит датасет по колонкам как в массиве columns\n",
    "df.columns = columns.split()\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# будем предсказывать True, если зарплата больше $50000, False иначе\n",
    "df['salary'] = df['salary'].apply((lambda x: x=='>50K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:19:20.805357Z",
     "start_time": "2020-10-11T11:19:20.783336Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_data = df[df.columns[numeric_indices]]\n",
    "\n",
    "categorial_data = df[df.columns[categorical_indices]]\n",
    "categorial_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:19:21.053858Z",
     "start_time": "2020-10-11T11:19:21.040860Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['education'].unique(), len(df['education'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку все алгоритмы машинного обучения, которые мы изучили, работают лишь с числовыми признаками, необходимо придумать способ обработки категориальных признаков, переводящий их в числовые. \n",
    "Одним из способов сделать это является **one-hot encoding**. Его суть состоит в следующем: пусть некоторая категориальная переменная (скажем, `color`) принимает $n$ различных значений (`Red`, `Yellow`, `Green`). Тогда можно создать $n$ новыx переменныx, соответствующих различным значениям категориального признака, каждая из которых равна $1$ в том случае, если изначальный категориальный признак принимает такое значение, и $0$ иначе. Принцип работы проиллюстрирован на картинке.\n",
    "\n",
    "<img src='../img/model_selection_ohe.png' width=600>\n",
    "\n",
    "В `pandas` one-hot encoding выполняется функцией `pd.get_dummies`. Сгенерируем one-hot признаки для нашего датасета. Сохраним полную матрицу объекты-признаки в переменную `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:19:36.657182Z",
     "start_time": "2020-10-11T11:19:36.622161Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_features = pd.get_dummies(categorial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:20:13.566890Z",
     "start_time": "2020-10-11T11:20:13.540891Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([numeric_data, dummy_features], axis=1)\n",
    "X_origin = df.iloc[:, :-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:20:20.520184Z",
     "start_time": "2020-10-11T11:20:20.517168Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:20:30.407526Z",
     "start_time": "2020-10-11T11:20:30.401526Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape, X_origin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь всё готово для обучения алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:20:37.886332Z",
     "start_time": "2020-10-11T11:20:37.881367Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:21:20.472653Z",
     "start_time": "2020-10-11T11:21:20.396622Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, визуализирующую поиск оптимального гиперпараметра модели по сетке. Используем идею кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:21:22.249967Z",
     "start_time": "2020-10-11T11:21:22.246968Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:21:23.221565Z",
     "start_time": "2020-10-11T11:21:23.212564Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_and_draw(X, y, model, param_name, grid, param_scale='ordinary', draw=True):\n",
    "    parameters = {param_name: grid}\n",
    "    \n",
    "    CV_model = GridSearchCV(estimator=model, \n",
    "                            param_grid=parameters,\n",
    "                            cv=5, \n",
    "                            scoring='f1',\n",
    "                            n_jobs=-1, \n",
    "                            verbose=10)\n",
    "    CV_model.fit(X, y)\n",
    "    means = CV_model.cv_results_['mean_test_score']\n",
    "    error = CV_model.cv_results_['std_test_score']\n",
    "    \n",
    "    if draw:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.title('choose ' + param_name)\n",
    "\n",
    "        if (param_scale == 'log'):\n",
    "            plt.xscale('log')\n",
    "\n",
    "        plt.plot(grid, means, label='mean values of score', color='red', lw=3)\n",
    "\n",
    "        plt.fill_between(grid, means - 2 * error, means + 2 * error, \n",
    "                         color='green', label='filled area between errors', alpha=0.5)\n",
    "        legend_box = plt.legend(framealpha=1).get_frame()\n",
    "        legend_box.set_facecolor(\"white\")\n",
    "        legend_box.set_edgecolor(\"black\")\n",
    "        plt.xlabel('parameter')\n",
    "        plt.ylabel('roc_auc')\n",
    "        plt.show()\n",
    "        \n",
    "    return means, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:21:24.463669Z",
     "start_time": "2020-10-11T11:21:24.459673Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:21:26.241652Z",
     "start_time": "2020-10-11T11:21:26.235657Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
    "param_names = ['n_neighbors', 'max_depth']\n",
    "grids = [np.array(np.linspace(4, 30, 8), dtype='int'), np.arange(1, 30)]\n",
    "param_scales = ['log', 'ordinary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:22:02.218673Z",
     "start_time": "2020-10-11T11:21:29.676670Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model, param_name, grid, param_scale in zip(models,\n",
    "                                                param_names,\n",
    "                                                grids,\n",
    "                                                param_scales):\n",
    "    search_and_draw(X_train, y_train, model, param_name, grid, param_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём параметр `n_estimators` для случайного леса. Известно, что случайный лес не переобучается, поэтому график качества будет монотонно возрастать. Следовательно, необходимо найти минимальное значение `n_estimators`, при котором качество не изменяется. \n",
    "Поскольку каждое дерево обучается независимо от остальных, достаточно обучить сразу лес из большого количества деревьев, а затем рассмотреть подмножества нужного размера из исходного множества деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:22:02.224658Z",
     "start_time": "2020-10-11T11:22:02.220675Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:22:02.234669Z",
     "start_time": "2020-10-11T11:22:02.227643Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:22:46.380628Z",
     "start_time": "2020-10-11T11:22:02.236622Z"
    }
   },
   "outputs": [],
   "source": [
    "max_trees = 100\n",
    "\n",
    "values = np.arange(max_trees) + 1\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "global_scores = []\n",
    "\n",
    "for train_indices, val_indices in tqdm(kf.split(X_train), total=5):\n",
    "    scores = []\n",
    "    \n",
    "    X_train_kf = X_train[train_indices]\n",
    "    y_train_kf = y_train[train_indices]\n",
    "    \n",
    "    X_val_kf = X_train[val_indices]\n",
    "    y_val_kf = y_train[val_indices]\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=max_trees)\n",
    "    forest.fit(X_train_kf, y_train_kf)\n",
    "    trees = forest.estimators_\n",
    "    \n",
    "    for number_of_trees in tqdm(values, leave=False):\n",
    "        thinned_forest = RandomForestClassifier(n_estimators=number_of_trees)\n",
    "        \n",
    "        thinned_forest.n_classes_ = 2\n",
    "        thinned_forest.estimators_ = trees[:number_of_trees]\n",
    "\n",
    "        scores.append(roc_auc_score(y_val_kf, thinned_forest.predict_proba(X_val_kf)[:, 1]))\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    global_scores.append(scores)\n",
    "\n",
    "global_scores = np.stack(global_scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:22:52.934021Z",
     "start_time": "2020-10-11T11:22:52.547993Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_cross_val_score = global_scores.mean(axis=0)\n",
    "std_cross_val_score = global_scores.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title('Quality of random forest')\n",
    "\n",
    "plt.plot(values, mean_cross_val_score, label='mean values', color='red', lw=3)\n",
    "plt.fill_between(values, \n",
    "                 mean_cross_val_score - 2 * std_cross_val_score, \n",
    "                 mean_cross_val_score + 2 * std_cross_val_score, \n",
    "                 color='green', \n",
    "                 label='filled area between errors',\n",
    "                 alpha=0.5)\n",
    "legend_box = plt.legend(framealpha=1).get_frame()\n",
    "legend_box.set_facecolor(\"white\")\n",
    "legend_box.set_edgecolor(\"black\")\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('roc-auc')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормировка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормируем признаки и проделаем тот же эксперимент с алгоритмом ближайших соседей. Посмотрим, изменилось ли качество предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:22:57.326128Z",
     "start_time": "2020-10-11T11:22:57.207981Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler` выполняет преобразование\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}, \\text{где $\\sigma$ - стандартное отклонение, а  $\\mu$ - среднее}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:55.521138Z",
     "start_time": "2020-10-11T11:23:08.372146Z"
    }
   },
   "outputs": [],
   "source": [
    "search_and_draw(X_train_scaled, y_train, KNeighborsClassifier(), 'n_neighbors', \n",
    "                np.array(np.linspace(4, 30, 8), dtype='int'), 'log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и следовало ожидать, ни один из наших алгоритмов не побил случайный лес. Итак, видим, что на больших выборках бэггинг работает. Вычислим итоговое качество на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:56.637237Z",
     "start_time": "2020-10-11T11:26:55.523147Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_train_predicted = model.predict_proba(X_train)[:, 1]\n",
    "y_test_predicted = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:56.642963Z",
     "start_time": "2020-10-11T11:26:56.638959Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:56.974994Z",
     "start_time": "2020-10-11T11:26:56.647965Z"
    }
   },
   "outputs": [],
   "source": [
    "train_auc = roc_auc_score(y_train, y_train_predicted)\n",
    "test_auc = roc_auc_score(y_test, y_test_predicted)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(*roc_curve(y_train, y_train_predicted)[:2], label=f'train AUC = {train_auc:.4f}')\n",
    "plt.plot(*roc_curve(y_test, y_test_predicted)[:2], label=f'test AUC = {test_auc:.4f}')\n",
    "legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()\n",
    "legend_box.set_facecolor(\"white\")\n",
    "legend_box.set_edgecolor(\"black\")\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что ещё можно делать:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подбирали оптимальный одномерный параметр для алгоритма. Можно также:\n",
    "\n",
    "* Искать по сетке не только численные гиперпараметры, но и категориальные, например, метрику в алгоритме ближайших соседей или критерий ветвления в решающем дереве.\n",
    "\n",
    "* Искать оптимальный параметр по многомерной сетке. Перебрать все возможные варианты здесь не выйдет, потому что на это уйдёт слишком много времени. Зато можно перебирать случайные точки по сетке. Эта процедура называется Grid Random Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея стекинга состоит в том, чтобы обучать разнообразные алгоритмы и использовать их в качестве новых признаков объектов.\n",
    "\n",
    "Чтобы избежать переобучения, необходимо разделить обучающую выборку на $n$ фолдов. Для предсказания ответов на $k$-ом фолде алгоритм обучается на оставшихся $n-1$ фолдах и предсказывает ответ на $k$-ом фолде. Такую схему обучения-предсказания реализует функция `sklearn.model_selection.cross_val_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:56.980962Z",
     "start_time": "2020-10-11T11:26:56.976965Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с тем же самым датасетом, что и ранее. Посмотрим, сумеем ли мы побить результаты случайного леса с помощью стекинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:56.991963Z",
     "start_time": "2020-10-11T11:26:56.983964Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_meta_feature(model, X_train, X_test, y_train, cv):\n",
    "    try:\n",
    "        train_answers = cross_val_predict(model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "        model.fit(X_train, y_train)\n",
    "        return train_answers, model.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        train_answers = cross_val_predict(model, X_train, y_train, cv=cv, method='predict')[:, 1]\n",
    "        model.fit(X_train, y_train)\n",
    "        return train_answers, model.predict(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:57.001966Z",
     "start_time": "2020-10-11T11:26:56.994962Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:57.014967Z",
     "start_time": "2020-10-11T11:26:57.004965Z"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(KNeighborsClassifier(n_jobs=-1, n_neighbors=30))\n",
    "models.append(LogisticRegression())\n",
    "models.append(RandomForestClassifier(max_depth=3, n_estimators=50, n_jobs=-1))\n",
    "models.append(RandomForestClassifier(max_depth=7, n_estimators=50, n_jobs=-1))\n",
    "models.append(DecisionTreeClassifier(max_depth=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:26:57.030960Z",
     "start_time": "2020-10-11T11:26:57.018968Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_features_train = np.zeros((X_train.shape[0], 0))\n",
    "meta_features_test = np.zeros((X_test.shape[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:27:12.749658Z",
     "start_time": "2020-10-11T11:26:57.035963Z"
    }
   },
   "outputs": [],
   "source": [
    "for model in tqdm(models):\n",
    "    train, test = compute_meta_feature(model, X_train, X_test, y_train, 5)\n",
    "    meta_features_train = np.append(meta_features_train, train.reshape((train.size, 1)), axis=1)\n",
    "    meta_features_test = np.append(meta_features_test, test.reshape((test.size, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:27:12.843627Z",
     "start_time": "2020-10-11T11:27:12.751643Z"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model = LogisticRegression()\n",
    "stacking_model.fit(meta_features_train, y_train)\n",
    "\n",
    "y_train_predicted = stacking_model.predict_proba(meta_features_train)[:, 1]\n",
    "y_test_predicted = stacking_model.predict_proba(meta_features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:27:13.190633Z",
     "start_time": "2020-10-11T11:27:12.845629Z"
    }
   },
   "outputs": [],
   "source": [
    "train_auc = roc_auc_score(y_train, y_train_predicted)\n",
    "test_auc = roc_auc_score(y_test, y_test_predicted)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(*roc_curve(y_train, y_train_predicted)[:2], label=f'train AUC = {train_auc:.4f}')\n",
    "plt.plot(*roc_curve(y_test, y_test_predicted)[:2], label=f'test AUC = {test_auc:.4f}')\n",
    "legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()\n",
    "legend_box.set_facecolor(\"white\")\n",
    "legend_box.set_edgecolor(\"black\")\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем в пару-тройку строк побить всё то качество, которое мы так усердно искали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если этого модуля нет, то нужно раскомментировать следующую строчку и запустить\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:28:06.684705Z",
     "start_time": "2020-10-11T11:28:06.681692Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:28:27.128797Z",
     "start_time": "2020-10-11T11:28:07.577620Z"
    }
   },
   "outputs": [],
   "source": [
    "boosting_model = xgboost.XGBClassifier(n_estimators=500)\n",
    "\n",
    "boosting_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = boosting_model.predict_proba(X_train)[:, 1]\n",
    "y_test_predicted = boosting_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:28:27.445649Z",
     "start_time": "2020-10-11T11:28:27.131613Z"
    }
   },
   "outputs": [],
   "source": [
    "train_auc = roc_auc_score(y_train, y_train_predicted)\n",
    "test_auc = roc_auc_score(y_test, y_test_predicted)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(*roc_curve(y_train, y_train_predicted)[:2], label=f'train AUC = {train_auc:.4f}')\n",
    "plt.plot(*roc_curve(y_test, y_test_predicted)[:2], label=f'test AUC = {test_auc:.4f}')\n",
    "legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()\n",
    "legend_box.set_facecolor(\"white\")\n",
    "legend_box.set_edgecolor(\"black\")\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Круто, да? А теперь попробуем \"отечественного\" производителя - `CatBoost` от Яндекса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если этого модуля нет, то нужно раскомментировать следующую строчку и запустить\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:51:29.433169Z",
     "start_time": "2020-10-11T11:51:29.429171Z"
    }
   },
   "outputs": [],
   "source": [
    "# документация: https://catboost.ai/docs\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:51:31.665855Z",
     "start_time": "2020-10-11T11:51:31.628858Z"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoost умеет работать с категориальными признаками сам\n",
    "X_train_origin, X_test_origin, _, _ = train_test_split(X_origin.values, y.values, \n",
    "                                                       train_size=0.8,\n",
    "                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/model_selection_one_hot.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:51:52.344278Z",
     "start_time": "2020-10-11T11:51:34.612167Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boosting_model = catboost.CatBoostClassifier(n_estimators=200, cat_features=categorical_indices)\n",
    "\n",
    "boosting_model.fit(X_train_origin, y_train)\n",
    "\n",
    "y_train_predicted = boosting_model.predict_proba(X_train_origin)[:, 1]\n",
    "y_test_predicted = boosting_model.predict_proba(X_test_origin)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:51:57.285685Z",
     "start_time": "2020-10-11T11:51:56.847671Z"
    }
   },
   "outputs": [],
   "source": [
    "train_auc = roc_auc_score(y_train, y_train_predicted)\n",
    "test_auc = roc_auc_score(y_test, y_test_predicted)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(*roc_curve(y_train, y_train_predicted)[:2], label=f'train AUC = {train_auc:.4f}')\n",
    "plt.plot(*roc_curve(y_test, y_test_predicted)[:2], label=f'test AUC = {test_auc:.4f}')\n",
    "legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()\n",
    "legend_box.set_facecolor(\"white\")\n",
    "legend_box.set_edgecolor(\"black\")\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:06:59.237838Z",
     "start_time": "2020-10-11T11:58:19.510026Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boosting_model = catboost.CatBoostClassifier(n_estimators=200, silent=True,\n",
    "                                             cat_features=categorical_indices,\n",
    "                                             eval_metric='AUC')\n",
    "boosting_model.grid_search({'l2_leaf_reg': np.linspace(0, 1, 20)}, \n",
    "                           X_train_origin, \n",
    "                           y_train, plot=True, refit=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
