{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"align: center;\">\n",
    "    <img align=center src=\"../img/dls_logo.jpg\" width=500 height=500>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"text-align: center;\">\n",
    "    Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ\n",
    "</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">\n",
    "    <b>Оптимизация и градиентный спуск</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AF4MsnKVg--3"
   },
   "source": [
    "## Оптимизация функций одной переменной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smbncR4CvDmh"
   },
   "source": [
    "### Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oy646ASQhIB4"
   },
   "source": [
    "Одна из самых важных задач, связанных с функциями - это задача **поиска минимума функции** или **задача оптимизации функции**.\n",
    "\n",
    "Эта задача решается нейронными сетями при обучении. Да, по сути, обучение нейронной сети - это оптимизация одной большой и очень сложной функции с тысячами или даже миллионами аргументов.\n",
    "\n",
    "При обучении нейронной сети мы хотим измерять, насколько хорошо сеть справляется с поставленной задачей. Для этого вводится **функция потерь** - такая функция, которая в качестве аргументов принимает правильные ответы и ответы нейронной сети, и выдает некоторое число - ошибку. Понятно, что мы хотим, чтобы ошибка сети была минимальной. То есть, ставится задача **минимизации функции потерь**. Мы хотим подобрать такие аргументы (параметры) нейронной сети, чтобы получить минимум функции потерь.\n",
    "\n",
    "Сейчас мы научимся минимизировать функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZQbYWqLvFpp"
   },
   "source": [
    "### Аналитический алгоритм поиска минимума функции одной переменной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8UPfz74pD_r"
   },
   "source": [
    "Вспомним, что в ноутбуке по производным мы выяснили, что знак производной функции в точке показывает характер изменения функции в этой точке - убывает она, возрастает или имеет локальный экстремум. Давайте сформулируем **необходимое и достаточное условия существования экстремума функции $F$ в точке $x$**:\n",
    "\n",
    "1. **Необходимое условие:** если функция $F$ имеет экстремум в точке $x$, то либо $F$ не имеет производной в точке $x$, либо $F'(x) = 0$.\n",
    "\n",
    "2. **Достаточное условие:** если функция $F$ имеет производную в окрестности точки $x$ и производная меняет знак при переходе через эту точку, то в точке $x$ функция $F$ имеет экстремум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOUz6DMrrLYp"
   },
   "source": [
    "Далее в курсе мы будем рассматривать только дифференцируемые на всей области определения функции (т.е. имеющие производную на всей области определения)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-HGvEOPsKCs"
   },
   "source": [
    "Заметим, что мы говорили сейчас об **экстремумах**, а не **точках минимума**. Если в точке $x$ функция имеет экстремум, то это может быть как точкой минимума, так и точкой максимума.\n",
    "\n",
    "Чтобы убедиться, что точка является точкой минимума, надо взять вторую производную $F''(x)$. Если $F'(x) = 0$ и $F''(x) > 0$, то $x$ - точка минимума, если же $F'(x) = 0$ и $F''(x) < 0$, то $x$ - точка максимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSi46EGmstok"
   },
   "source": [
    "Итак, **алгоритм нахождения точек локального минимума функции $F(x)$** (только для гладких функций):\n",
    "\n",
    "1. Найти корни уравнения $F'(x) = 0$ (найти те точки $x$, в которых производная равна 0).\n",
    "\n",
    "2. Для всех корней уравнения $x_i$ вычислить вторую производную $F''(x_i)$. Если она больше нуля, то это точка минимума.\n",
    "\n",
    "Этот алгоритм **аналитический** - он основан на решении уравнений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZPJXsSotP6P"
   },
   "source": [
    "#### Пример 1\n",
    "\n",
    "Рассмотрим функцию $F = 4x^2 - 3x + 5$. Найдем точки минимума этой функции:\n",
    "\n",
    "1. Находим производную: $F'(x) = 8x - 3$.\n",
    "\n",
    "2. Решаем уравнение $F'(x) = 8x - 3 = 0$, $x = \\frac{3}{8}$ - получили единственный корень.\n",
    "\n",
    "3. Находим вторую производную функции $F$ в точке $\\frac{3}{8}$: $F''(x) = (8x - 3)' = 8 > 0$, поэтому полученная точка экстремума $x = \\frac{3}{8}$ - точка минимума.\n",
    "\n",
    "Получается, что мы нашли единственную точку минимума $x = \\frac{3}{8}$.\n",
    "\n",
    "Мы можем убедиться в правильности решения, посмотрев на график функции $F$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:16:41.678960Z",
     "start_time": "2020-03-20T19:16:41.374258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "dVWJsK2uhC4y",
    "outputId": "766cf33e-87ce-45fb-ccb6-1d99d1710908"
   },
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return 4 * x**2 - 3 * x + 5\n",
    "   \n",
    "x = np.linspace(-1, 2, 100)\n",
    "y = F(x)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.scatter([3 / 8], [F(3 / 8)], lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECa-6dCOwePp"
   },
   "source": [
    "Этот алгоритм хорошо работает и позволяет находить точные значения координаты точки минимума функции. Но он не всегда применим.\n",
    "\n",
    "Рассмотрим функцию, знакомую нам по ноутбуку по производным: $F(x) = x^4 + 5x^3 - 10x$. Выглядит она так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:17:06.829805Z",
     "start_time": "2020-03-20T19:17:06.492854Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "Y3t8nfaYvcjx",
    "outputId": "a6d5510f-7e83-4551-eb3f-1d7e023f7236"
   },
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return x**4 + 5 * x**3 - 10 * x\n",
    "\n",
    "x = np.linspace(-5, 2, 100)\n",
    "y = F(x)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.scatter([-3.5518, -0.9439, 0.7457], [F(-3.5518), F(-0.9439), F(0.7457)], lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXqAXzmlwxgE"
   },
   "source": [
    "Мы помним, что у неё есть две точки минимума и одна точка максимума. Давайте допустим, что мы хотим найти координаты точек минимума, используя наш алгоритм. Нам нужно было бы вычислить производную:\n",
    "\n",
    "$$\n",
    "F'(x) = 4x^3 + 15x^2 -10\n",
    "$$\n",
    "\n",
    "и решить уравнение:\n",
    "\n",
    "$$\n",
    "4x^3 + 15x^2 -10 = 0\n",
    "$$\n",
    "\n",
    "Но это уравнение третьей степени, которое сложно решить аналитически. Значит, найти точки минимума нашим алгоритмом не получится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YytARbPIxlEh"
   },
   "source": [
    "Очевидно, бывают ещё более сложные функции, что уж говорить о функциях многих переменных. Поэтому рассмотрим другой алгоритм поиска минимума функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JTs_CLJxyzZ"
   },
   "source": [
    "## Алгоритм градиентного спуска: идея"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcAtHF-ZyCQm"
   },
   "source": [
    "Посмотрим на график этой коварной функции и на случайную точку $(x, y)$ на нём:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:18:49.499073Z",
     "start_time": "2020-03-20T19:18:49.185436Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "_SiGJ1apxd_V",
    "outputId": "c7f57e74-6ae5-468e-d906-c2ce6c1fadfe"
   },
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return x**4 + 5 * x**3 - 10 * x\n",
    "\n",
    "x = np.linspace(-5, 2, 100)\n",
    "y = F(x)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.scatter([-2], [F(-2)], lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "URH7uH9PIp8u"
   },
   "source": [
    "Давайте представим, что мы не видим графика этой функции, но очень хотим найти точку минимума функции.\n",
    "\n",
    "Из ноутбука по производным мы помним, что знак производной функции в точке показывает, возрастает функция в этой точке или убывает (ну или имеет экстремум). Как нетрудно догадаться, производная в точке $(x, y)$ на нашем графике будет $< 0$, функция в этой точке возрастает.\n",
    "\n",
    "Это значит, что **какая-то точка локального минимума функции находится левее точки $x$** (\"левее\" значит, что минимум функции достигается при значении аргумента $< x$). Это отличное наблюдение! Это значит, что если мы уменьшим $x$ на некоторую величину $\\Delta x$, то мы можем стать ближе к точке минимума!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sppzD64HIrBt"
   },
   "source": [
    "Тогда алгоритм поиска точки минимума выглядит так:\n",
    "\n",
    "1. Берём случайную точку $x$ функции $F$.\n",
    "\n",
    "2. Вычисляем производную $F'(x)$.\n",
    "\n",
    "3. Если $F'(x) > 0$, уменьшаем $x$, если $F'(x) < 0$, увеличиваем $x$.\n",
    "\n",
    "4. Повторяем пункты 2 и 3. \n",
    "\n",
    "То есть, мы берём случайную точку и начинаем движение от неё к точке минимума, каждый шаг алгоритма вычисляя производную функции в точке, в которой сейчас находимся и сдвигая эту точку в направлении минимума.\n",
    "\n",
    "Вычислять производную на каждом шаге нужно, потому что мы в какой-то момент можем \"перепрыгнуть\" через точку минимума, тогда производная поменяет знак и мы поймём, что нужно двигаться обратно.\n",
    "\n",
    "В идеале это \"движение\" должно выглядеть так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcTbeu4sKGsf"
   },
   "source": [
    "<img src=\"../img/linear_models_optimization_1.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTrwC5lG_cN6"
   },
   "source": [
    "Остаётся два вопроса: на какую величину $\\Delta x$ уменьшать и когда останавливать алгоритм.\n",
    "\n",
    "Давайте попробуем выбрать $\\Delta x$. Это нетривиально, ведь мы не видим графика функции и не знаем, насколько далеко точка минимума. А численное значение производной нам показывает только факт убывания функции и скорость убывания (угол наклона графика), но не расстояние до точки минимума.\n",
    "\n",
    "Другими словами, минимум может быть в точке $x - 0.2$, а может быть и в точке $x - 200$. \n",
    "\n",
    "Если мы возьмём слишком большую величину, то можем просто перескочить через точку минимума. Примером такой величины может быть $\\Delta x = 2.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T19:23:29.116710Z",
     "start_time": "2020-03-20T19:23:28.782835Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "QaS2QFV89lEY",
    "outputId": "9d1fdce2-170c-4d8d-ca42-ba8ef82a6b04"
   },
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return x**4 + 5 * x**3 - 10 * x\n",
    "\n",
    "x = np.linspace(-5, 2, 100)\n",
    "y = F(x)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.scatter([-2, -4.5], [F(-2), F(-4.5)], lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwHOjaK6ExA2"
   },
   "source": [
    "Итак, нужно брать $\\Delta x$ довольно маленьким.\n",
    "\n",
    "Если мы зафиксируем некоторую величину $\\Delta x$ и на каждом шаге алгоритма будем сдвигать $x$ на одинаковую величину $\\Delta x$ в направлении минимума, то это может занять очень много времени (например, когда точка минимума в точке $x = 1$, а мы стоим в точке $x = 1001$ и $\\Delta x = 1$, нам потребуется $1000$ шагов алгоритма, чтобы дойти до минимума). Плюс, если мы стоим в точке $x = 1.5$, то, сдвинувшись на $\\Delta x = 1$ по направлению к точке минимума, мы попадём в точку $x = 0.5$. Далее, опять сдвинувшись на $\\Delta x = 1$ по направлению к точке минимума, мы попадём в точку $x = 1.5$ и будем так ходить туда-сюда, не приближаясь к точке минимума $x = 1$ ближе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIiJeLP3FZG0"
   },
   "source": [
    "Давайте ещё раз внимательно посмотрим на график функции и заметим, что чем ближе точка к минимуму, тем плавнее график. Более формально, чем ближе точка к минимуму, тем меньше скорость изменения функции, а значит, тем меньше модуль значения производной.\n",
    "\n",
    "Мы можем это использовать. Давайте зафиксируем некоторое маленькое число $\\varepsilon$ и каждый шаг алгоритма будем двигать $x$ по направлению к минимуму на шаг $\\varepsilon \\cdot |F'(x)|$. Тогда, пока наша точка будет далеко от минимума, $|F'(x)|$ будет довольно большим и мы будем двигаться большими шагами, а по мере приближения к точке минимума $|F'(x)|$ будет уменьшаться, и наш шаг тоже будет уменьшаться. Так мы менее вероятно перескочим через точку минимума и в итоге подойдём к ней ближе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Us3jbxBPQYBx"
   },
   "source": [
    "Ответ на второй вопрос - когда останавливать алгоритм поиска минимума - может быть разным. Действуя таким образом, ровно в точку минимума мы почти никогда не попадём, придётся остановиться в какой-то точке возле минимума. Но для применения этого алгоритма нахождения точки в окрестности минимума вполне хватает. Чаще всего алгоритм останавливается после прохождения определенного количества шагов и/или достижения определенной близости к точке минимума. Близость, опять же, можно измерять значением производной в точке. Чем ближе, тем модуль производной меньше.\n",
    "\n",
    "Теперь мы можем сформулировать итоговый алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFOSF91fQFwy"
   },
   "source": [
    "## Алгоритм градиентного спуска "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkXSHxXrUHYx"
   },
   "source": [
    "1. Берём некоторую точку $x$ функции $F$, фиксируем $\\varepsilon$ (например, $\\varepsilon = 0.001$).\n",
    "\n",
    "\n",
    "2. Вычисляем производную $F'(x)$.\n",
    "\n",
    "\n",
    "3. Изменяем $x$: $x = x - \\varepsilon F'(x)$.\n",
    "\n",
    "\n",
    "4. Повторяем третий пункт, пока не пройдёт определенное количество шагов и/или мы не станем достаточно близко к точке минимума.\n",
    "\n",
    "\n",
    "Этот алгоритм называется **алгоритмом градиентного спуска**. Градиентного - потому что мы \"спускаемся\" к точке минимума, вычисляя производную (градиент) функции на каждом шаге.\n",
    "\n",
    "Выглядит это как-то так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9LzMHhcZSFo3"
   },
   "source": [
    "<img src=\"../img/linear_models_optimization_2.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9up3-ZTRDCS"
   },
   "source": [
    "Заметим, что начиная движение из одной точки, мы можем найти только одну точку локального минимума. Если хочется найти несколько точек, можно запустить алгоритм градиентного спуска несколько раз из разных случайно выбранных точек. Но гарантии, что мы найдём все точки минимума или что найдём точку глобального минимума, нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "983ypt_BTzvW"
   },
   "source": [
    "Существует множество модификаций и оптимизаций алгоритма градиентного спуска, но о них мы говорить не будем. Центральная идея у них одна и та же - спуск к точке минимума, используя градиент функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txUBjU1AULu2"
   },
   "source": [
    "## Оптимизация функций многих переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDs00e4nUPVD"
   },
   "source": [
    "Давайте перейдём к функциям многих переменных. \n",
    "\n",
    "Идея нахождения минимума функции многих переменных такая же, как и для функции одной переменной. \n",
    "\n",
    "Давайте рассмотрим функцию $F(x_1, x_2, \\ldots, x_n)$ $n$ переменных. Алгоритм выглядит так:\n",
    "\n",
    "1. Берём некоторую точку $x = (x_1, x_2, \\ldots, x_n)$ функции, фиксируем $\\varepsilon$ (например, $\\varepsilon = 0.001$).\n",
    "\n",
    "\n",
    "2. Вычисляем частные производные $F'_{x_k}(x)$ по всем $n$ аргументам функции в точке $x = (x_1, x_2, \\ldots, x_n)$, получаем градиент:\n",
    "\n",
    "$$\n",
    "\\nabla F = (F'_{x_1}(x_1, x_2, \\ldots, x_n), F'_{x_2}(x_1, x_2, \\ldots, x_n), \\ldots, F'_{x_n}(x_1, x_2, \\ldots, x_n)) = \\left(\\frac{\\partial F}{\\partial x_1}(x_1, x_2, \\ldots, x_n),\\frac{\\partial F}{\\partial x_2}(x_1, x_2, \\ldots, x_n), \\ldots, \\frac{\\partial F}{\\partial x_n}(x_1, x_2, \\ldots, x_n)\\right)\n",
    "$$\n",
    "\n",
    "3. Сдвигаемся:\n",
    "\n",
    "$$\n",
    "x_1 : x_1 = x_1 - \\varepsilon F'_{x_1}(x_1, x_2, \\ldots, x_n)\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_2 : x_2 = x_2 - \\varepsilon F'_{x_2}(x_1, x_2, \\ldots, x_n)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\cdots\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_n : x_n = x_n - \\varepsilon F'_{x_n}(x_1, x_2, \\ldots, x_n)\n",
    "$$\n",
    "\n",
    "или в векторной записи:\n",
    "\n",
    "$$\n",
    "x = x - \\varepsilon \\nabla F(x)\n",
    "$$\n",
    "\n",
    "4. Повторяем третий пункт, пока не пройдёт определенное количество шагов и/или мы не станем достаточно близко к точке минимума по каждой из координат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fD0EtDDlXXnM"
   },
   "source": [
    "То есть мы вычисляем частные производные по каждому аргументу функции, понимаем для каждого аргумента функции, возрастает или убывает функция по этому аргументу и меняем значения всех $n$ аргументов в ту сторону, где функция убывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1T2C2T90ZUwr"
   },
   "source": [
    "В случае функции двух переменных алгоритм может выглядеть так:\n",
    "\n",
    "<img src=\"../img/linear_models_optimization_3.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение:** вычислите шаг градиентного спуска фукнции $F(x_1,x_2,x_3,x_4)=x_1\\cdot x_2 + x_3^5 + e^{x_4}$ для некоторого фиксированного $\\varepsilon$ и начального приближения $x_0=(x_1^0,x_2^0, x_3^0,x_4^0)$. Выпишите формулу градиентного спуска в этом случае."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Optimization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
