{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTv7FBBwus9R"
   },
   "source": [
    "<p style=\"align: center;\">\n",
    "    <img align=center src=\"../img/dls_logo.jpg\" width=500 height=500>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"text-align: center;\">\n",
    "    Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ\n",
    "</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kg1PNd3Yus9T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs3BGhfQus9X"
   },
   "source": [
    "Сгенерируем датасет \"Игрушка Дьявола\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrBu0Ehous9Z"
   },
   "outputs": [],
   "source": [
    "# код для генерации взят из Стэнфордсокго курса:\n",
    "# http://cs231n.github.io/neural-networks-case-study/#linear\n",
    "\n",
    "N = 100\n",
    "D = 2\n",
    "K = 3\n",
    "X = np.zeros((N * K, D))\n",
    "y = np.zeros(N * K, dtype='uint8')\n",
    "\n",
    "for j in range(K):\n",
    "    ix = range(N * j, N * (j + 1))\n",
    "    r = np.linspace(0, 1, N)\n",
    "    t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n",
    "    X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "    y[ix] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "U48Jr8Lcus_c",
    "outputId": "1234bc7c-1f53-4c82-9add-c7fc6cfa9a12"
   },
   "outputs": [],
   "source": [
    "# отрисовочная магия, снова взято из\n",
    "# http://cs231n.github.io/neural-networks-case-study/#linear\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.rainbow)\n",
    "\n",
    "plt.title('Игрушка дьявола', fontsize=15)\n",
    "plt.xlabel('$x$', fontsize=14)\n",
    "plt.ylabel('$y$', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHlSp5kYus_g"
   },
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X)\n",
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EFQnAFZus_o"
   },
   "source": [
    "Сейчас мы хотим научиться самостоятельно создавать наследников `nn.Module`. До этого мы делали нейросети с помощью класса `nn.Sequential`, попробуем построить такую же сеть, как на прошлом семинаре, но самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvU79PYbus_p"
   },
   "outputs": [],
   "source": [
    "# сеть с прошлого семинара\n",
    "\n",
    "# D_in - размерность входа (количество признаков у объекта)\n",
    "# H - размерность скрытых слоёв\n",
    "# D_out - размерность выходного слоя (количество классов)\n",
    "D_in, H, D_out = 2, 100, 3\n",
    "\n",
    "# use the nn package to define our model and loss function\n",
    "two_layer_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVdGTR1uus_t"
   },
   "source": [
    "Что такое модуль и как он устроен? Во-первых, модуль это такой строительный блок для нейронок, с помощью модуля можно задать любую дифференциируемую по своему параметру функцию. Применяются модули так же, как и обычные функции с синтаксисом\n",
    "\n",
    "```python\n",
    "module_instance(var1, var2)\n",
    "```\n",
    "\n",
    "При этом внутри вызывается функция `forward` с теми же аргументами, а её выход возвращается как результат вызова модуля. Зачем же нужно так странно оборачивать обычные функции в модули? \n",
    "\n",
    "Это позволяет очень удобно следить за параметрами, которые надо изменять. Когда мы хотим получить все параметры, можно просто рекурсивно пройтись по всем полям модели, посмотреть, какие из них являются параметрами сами по себе, а какие являются модулями и содержат параметры внутри, а потом всё это объединить.\n",
    "\n",
    "По этой причине, если вы используете внутри своего модуля какие-то ещё модули, их надо класть просто в поле класса, если это единичный модуль, и в класс **nn.ModuleList** или **nn.ModuleDict**, если у вас список или словарь используемых модулей. Если же в модели у вас есть какой-то собственный вес, то недостаточно положить тензор в поле класса, его надо обернуть в **nn.Parameter**, **nn.ParameterList** или **nn.ParameterDict** в зависимотси от того, какой именно у вас случай.\n",
    "\n",
    "Такая организация позволяет достаточно безболезненно расширять **PyTorch** и писать для него свои функции, которые нельзя выразить композицией уже существующих. Пригождается это редко, поэтому сегодня мы не будем писать свое расширение.\n",
    "\n",
    "Код, разделенный на модули - это просто красиво."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btTu1OI7us_u"
   },
   "outputs": [],
   "source": [
    "# новая сеть\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f_lin = nn.Linear(D_in, H)\n",
    "        self.s_lin = nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.f_lin(X))\n",
    "        return F.softmax(self.s_lin(X), dim=1)\n",
    "    \n",
    "model = MyModule()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), 1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO5mGiYxk1du"
   },
   "source": [
    "Поговорим поподробнее о `softmax` и `CrossEntropyLoss`.\n",
    "\n",
    "Напоминание: softmax-функция выглядит следующим образом:\n",
    "\n",
    "$$\n",
    "Softmax(x) =\n",
    "\\begin{pmatrix} \n",
    "    \\dfrac{e^{x_1}}{\\sum\\limits_{i=0}^{m} e^{x_i}},\\; \\dots,\\; \\dfrac{e^{x_m}}{\\sum\\limits_{i=0}^{m} e^{x_i}}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Таким образом, после применения softmax-функции мы получили вектор чисел из интервала $(0, 1)$, которые мы будем интерпретировать как вероятности классов.\n",
    "\n",
    "Аналогично тому, как мы обощили сигмоиду на многоклассовый случай и получили softmax, можно обобщить и функцию потерь, получив **кросс-энтропию**:\n",
    "\n",
    "$$\n",
    "CrossEntropy(x) = -\\sum\\limits_{i=0}^m y_i \\cdot log(Softmax(x)_i)\n",
    "$$\n",
    "\n",
    "где $y_i$ – истинная метка класса ($1$ если $x$ принадлежит $i$-ому классу и $0$ иначе)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "LKI26rSzus_x",
    "outputId": "6a5d212b-1903-40c9-d815-b3a3393c06e9"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for t in range(100):\n",
    "    # forward\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxv6-IAdus_4"
   },
   "source": [
    "Теперь посмотрим, что будет, если не положить используемые внутри слои в `self`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RYJAGLFBus_5",
    "outputId": "912d5d33-5440-4208-e9da-71d5ddcfcf9a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# сеть без параметров\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layers = [nn.Linear(D_in, H), nn.Linear(H, D_out)]\n",
    "        self.my_useless_bias = torch.ones(1, H, requires_grad=True)\n",
    "        self.more_of_my_useless_biases = [\n",
    "            torch.ones(1, H, requires_grad=True),\n",
    "            torch.ones(1, H, requires_grad=True),\n",
    "            torch.ones(1, H, requires_grad=True),\n",
    "        ]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear_layers[0](X))\n",
    "        X += self.my_useless_bias\n",
    "        return F.softmax(self.linear_layers[1](X), dim=1)\n",
    "    \n",
    "model = MyModule()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceeZBYFwus_8"
   },
   "source": [
    "Как мы и ожидали, параметров нет. Исправим это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9uJCCwb9us_9",
    "outputId": "3ab4801f-cc5a-45fb-ea11-91b981ac2d9f"
   },
   "outputs": [],
   "source": [
    "# исправленная сеть с параметрами\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(D_in, H), nn.Linear(H, D_out)])\n",
    "        self.my_useless_bias = nn.Parameter(torch.ones(1, H, requires_grad=True))\n",
    "        self.more_of_my_useless_biases = nn.ParameterList([\n",
    "            nn.Parameter(torch.ones(1, H, requires_grad=True)),\n",
    "            nn.Parameter(torch.ones(1, H, requires_grad=True)),\n",
    "            nn.Parameter(torch.ones(1, H, requires_grad=True))\n",
    "        ])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear_layers[0](X))\n",
    "        X += self.my_useless_bias\n",
    "        for b in self.more_of_my_useless_biases:\n",
    "            X += b\n",
    "        return F.softmax(self.linear_layers[1](X), dim=1)\n",
    "    \n",
    "model = MyModule()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHBifDNFutAA"
   },
   "source": [
    "Как мы и хотели, все параметры появились!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar]creating_module.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
